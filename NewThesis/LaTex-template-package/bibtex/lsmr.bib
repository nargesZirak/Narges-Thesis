% This file was created with JabRef 2.10.
% Encoding: Cp1252


@MastersThesis{2009:msc:bertram,
  Title                    = {The Social Nature of Issue Tracking in Small, Collocated Teams},
  Author                   = {Dane Bertram},
  School                   = {University of Calgary},
  Year                     = {2009},

  Address                  = {Calgary, Canada},
  Month                    = nov,
  Type                     = {MSc thesis},

  Abstract                 = {TBD}
}

@InProceedings{2010:cscw:bertram,
  Title                    = {Communication, collaboration, and bugs: The social nature of issue tracking in small, collocated teams},
  Author                   = {Dane Bertram and Amy Voida and Saul Greenberg and Robert Walker},
  Booktitle                = cscw,
  Year                     = {2010},
  Pages                    = {291--300},

  Abstract                 = {Issue tracking systems help organizations manage issue reporting, assignment, tracking, resolution, and archiving. Traditionally, it is the Software Engineering community that researches issue tracking systems, where software defects are reported and tracked as 'bug reports' within an archival database. Yet, as issue tracking is fundamentally a social process, it is important to understand the design and use of issue tracking systems from that perspective. Consequently, we conducted a qualitative study of issue tracking systems as used by small, collocated software development teams. We found that an issue tracker is not just a database for tracking bugs, features, and inquiries, but also a focal point for communication and coordination for many stakeholders within and beyond the software team. Customers, project managers, quality assurance personnel, and programmers all contribute to the shared knowledge and persistent communication that exists within the issue tracking system. These results were all the more striking because in spite of teams being collocated---which afforded frequent, face-to-face communication---the issue tracker was still used as a fundamental communication channel. We articulate various real-world practices surrounding issue trackers and offer design considerations for future systems.},
  Doi                      = {10.1145/1718918.1718972}
}

@MastersThesis{2008:msc:chang,
  Title                    = {Finding Relevant Starting Points with Source Code Indexes},
  Author                   = {Joseph J. C. Chang},
  School                   = {University of Calgary},
  Year                     = {2008},

  Address                  = {Calgary, Canada},
  Month                    = aug,

  Abstract                 = {TBD}
}

@InProceedings{2005:etx:chang,
  Title                    = {Incomplete resolution of references in {E}clipse},
  Author                   = {Joseph J. C. Chang and Robert J. Walker},
  Booktitle                = etx,
  Year                     = {2005},
  Note                     = {ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  Pages                    = {5--9},

  Abstract                 = {In the Eclipse JDT, the Java reference resolution rules are applied as fully as possible, thereby either determining the unique target for a given reference or signalling that the reference cannot be resolved. However, a variety of development tasks require the manipulation of code for which incomplete resolution of references is both possible and useful. This paper motivates the need for incomplete resolution during a software reuse-and-integration task and the difficulties that result. A proof-of-concept implementation is described that is used as a basis for reuse tool support and that can be used for other transformation tools.},
  Doi                      = {10.1145/1117696.1117697}
}

@InCollection{2004:book:filman:clarke,
  Title                    = {Generic aspect-oriented design with {Theme/UML}},
  Author                   = {Siobh\'an Clarke and Robert J. Walker},
  Booktitle                = {Aspect-Oriented Software Development},
  Publisher                = {Addison-Wesley},
  Year                     = {2004},
  Chapter                  = {19},
  Editor                   = {Robert E. Filman and Tzilla Elrad and Siobh\'an Clarke and Mehmet Ak{\c{s}}it},

  Abstract                 = {Requirements such as distribution or tracing have an impact on multiple classes in a system. Their support is, by necessity, scattered across those multiple classes. A look at an individual class may also show support for such crosscutting requirements (or aspects) tangled up with the core responsibilities of that class. Scattering and tangling make object-oriented software difficult to understand, extend, and reuse. Though design is an important activity within the software life cycle with welldocumented benefits, those benefits are reduced when crosscutting requirements are present. This chapter presents a means to mitigate these problems with Theme/UML. Theme/UML is an extension to standard UML to support the modularization of designs into ``themes.'' A theme is any feature, concern, or requirement of interest that must be handled in the system. This chapter focuses on themes that provide a design for behavior that crosscuts other behavior in the design. This chapter also demonstrates how crosscutting themes map to AspectJ and Hyper/J, two implementation approaches that provide a solution for separation of crosscutting requirements in source code. This mapping serves to illustrate that separation of aspects may be maintained throughout the software life cycle.}
}

@InProceedings{2002:aosd:clarke,
  Title                    = {Towards a standard design language for {AOSD}},
  Author                   = {Siobh\'an Clarke and Robert J. Walker},
  Booktitle                = aosd,
  Year                     = {2002},
  Pages                    = {113--119},

  Abstract                 = {For aspect-oriented software development (AOSD) to live up to being a software engineering method, there must be support for the separation of crosscutting concerns across the development lifecycle. Part of this support is traceability from one lifecycle phase to another.This paper investigates the traceability between one particular AOSD design-level language, Theme/UML, and one particular AOSD implementation-level language, AspectJ. This provides for a means to assess these languages and their incompatibilities, with a view towards eventually developing a standard design language for a broad range of AOSD approaches.},
  Doi                      = {10.1145/508386.508400}
}

@InProceedings{2001:asoc:clarke,
  Title                    = {Mapping composition patterns to AspectJ and Hyper/J},
  Author                   = {Siobh\'an Clarke and Robert J. Walker},
  Booktitle                = asoc,
  Year                     = {2001},
  Note                     = {International Conference on Software Engineering},
  Pages                    = {18--26},

  Abstract                 = {In earlier work, we demonstrated the successful separation of the designs of crosscutting concerns into composition patterns [1]. In this paper, we demonstrate the mapping of crosscutting designs to two programming models that support similar approaches to separation within code—AspectJ [7] and Hyper/J [5]. We first illustrate the design of the Observer pattern using the composition pattern approach, and then map that design to the appropriate code.},
  Url                      = {http://www.research.ibm.com/hyperspace/workshops/icse2001/Papers/clarke.pdf}
}

@InProceedings{2001:icse:clarke,
  Title                    = {Composition patterns: An approach to designing reusable aspects},
  Author                   = {Siobh\'an Clarke and Robert J. Walker},
  Booktitle                = icse,
  Year                     = {2001},
  Pages                    = {5--14},

  Abstract                 = {Requirements such as distribution or tracing have an impact on multiple classes in a system. They are cross-cutting requirements, or aspects. Their support is, by necessity, scattered across those multiple classes. A look at an individual class may also show support for cross-cutting requirements tangled up with the core responsibilities of that class. Scattering and tangling make object-oriented software difficult to understand, extend and reuse. Though design is an important activity within the software lifecycle with well-documented benefits, those benefits are reduced when cross-cutting requirements are present. This paper presents a means to mitigate these problems by separating the design of cross-cutting requirements into composition patterns. Composition patterns require extensions to the UML, and are based on a combination of the subject-oriented model for composing separate, overlapping designs, and UML templates. This paper also demonstrates how composition patterns map to one programming model that provides a solution for separation of cross-cutting requirements in code-aspect-oriented programming. This mapping serves to illustrate that separation of aspects may be maintained throughout the software lifecycle.},
  Doi                      = {10.1109/ICSE.2001.919076}
}

@TechReport{2001:tr:clarke,
  Title                    = {Separating Crosscutting Concerns Across the Lifecycle: From Composition Patterns to {AspectJ} and {Hyper/J}},
  Author                   = {Siobh\'an Clarke and Robert J. Walker},
  Institution              = {Trinity College, Dublin},
  Year                     = {2001},

  Address                  = {Dublin, Ireland},
  Number                   = {TCD-CS-2001-15},

  Abstract                 = {Requirements that have a crosscutting impact on software (such as distribution or persistence) present many problems for software development that manifest themselves throughout the lifecycle. Inherent properties of crosscutting requirements, such as scattering (where their support is scattered across multiple classes) and tangling (where their support is tangled with elements supporting other requirements), reduce the reusability, extensibility, and traceability of the affected software artefacts. Scattering and tangling exist both in designs and code and must therefore be addressed in both. To remove scattering and tangling properties, a means to separate the designs and code of crosscutting behaviour into independent models or programs is required. This paper discusses approaches that achieve exactly that in either designs or code, and presents an investigation into a means to maintain this separation of crosscutting behaviour seamlessly across the lifecycle. To achieve this, we work with composition patterns at the design level, AspectJ and Hyper/J at the code level, and investigate a mapping between the two levels. Composition patterns are a means to separate the design of crosscutting requirements in an encapsulated, independent, reusable, and extensible way. AspectJ and Hyper/J are technologies that provide similar levels of separation for Java code. We discuss each approach, and map the constructs from composition patterns to those of AspectJ and Hyper/J. We first illustrate composition patterns with the design of the Observer pattern, and then map that design to the appropriate code. As this is achieved with varying levels of success, the exercise also serves as a case study in using those implementation techniques.}
}

@TechReport{2014:uofc:cossette,
  Title                    = {Using Structural Generalization to Discover Replacement Functionality for {API} Evolution},
  Author                   = {Bradley Cossette and Robert Walker and Rylan Cottrell},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2014},

  Address                  = {Calgary, Canada},
  Month                    = may,
  Number                   = {2014-745-10}
}

@InProceedings{2010:fse:cossette,
  Title                    = {{DSketch}: Lightweight, adaptable dependency analysis},
  Author                   = {Brad Cossette and Robert J. Walker},
  Booktitle                = fse,
  Year                     = {2010},
  Pages                    = {297--306},

  Abstract                 = {Software developers who extend or repair existing software systems spend considerable effort in understanding how their modifications will require follow-on changes in order to work correctly. Tool support for this process is available for single, popular languages, but does not suffice for less popular languages, uncommon language variants, or arbitrary combinations of languages and connection technologies. We have created the DSketch tool so that developers can create a lightweight pattern specification for how dependencies can be heuristically identified in their systems. We performed two case studies involving industrial developers who applied our tool for conducting polylingual dependency analysis in software systems; the developers found it easy to configure the tool for their needs, were able to adapt their patterns to new contexts, and had sufficiently accurate dependency predictions for their work.},
  Doi                      = {10.1145/1882291.1882335}
}

@InProceedings{2007:icsm:cossette,
  Title                    = {Polylingual dependency analysis using island grammars: A cost versus accuracy evaluation},
  Author                   = {Brad Cossette and Robert J. Walker},
  Booktitle                = icsm,
  Year                     = {2007},
  Pages                    = {214--223},

  Abstract                 = {Software dependency analysis is an important step in determining the potential impact of changes. Existing tool support for conducting dependency analysis does not sufficiently support systems written in more than one language. Tools based on semantic analyses are expensive to create for combinations of multiple languages, while lexical tools provide poor accuracy and rely heavily on developer skill. This paper reports on an investigation into the application of a series of incrementally-better island grammars to an industrial, open-source polylingual system to determine the cost-to-accuracy relationship involved in developing and applying island grammars for dependency analysis. The results of our study suggest the effort-cost in writing richer island grammars rises faster than the resulting accuracy.},
  Doi                      = {10.1109/ICSM.2007.4362634}
}

@MastersThesis{2008:msc:cossette,
  Title                    = {Lightweight Support for Estimation of Polylingual Dependencies},
  Author                   = {Bradley E. Cossette},
  School                   = {University of Calgary},
  Year                     = {2008},

  Address                  = {Calgary, Canada},
  Month                    = aug,

  Abstract                 = {Software dependency analysis is an important step in determining the potential impact of changes to existing systems. Existing tool support for conducting dependency analysis does not sufficiently support systems written in more than one language. Tools based on semantic analysis are expensive to create for combinations of multiple languages, while lexical tools provide poor accuracy and rely heavily on developer skill.
This work proposes lightweight, approximate, polylingual dependency analysis tool support, by presuming which few semantics are important for such analysis, and requiring that developers only specify those syntactic patterns necessary to recognize these semantics. This work presents two studies conducted to evaluate (1) which semantics are of greatest use for such analysis, and (2) the ease-of-configuration, and effectiveness of such an approach, as implemented in the research prototype tool, GrammarSketch.}
}

@InProceedings{2012:fse:cossette,
  Title                    = {Seeking the ground truth: A retroactive study on the evolution and migration of software libraries},
  Author                   = {Bradley E. Cossette and Robert J. Walker},
  Booktitle                = fse,
  Year                     = {2012},
  Pages                    = {55:1--55:11},

  Abstract                 = {Application programming interfaces (APIs) are a common and industrially-relevant means for third-party software developers to reuse external functionality. Several techniques have been proposed to help migrate client code between library versions with incompatible APIs, but it is not clear how well these perform in an absolute sense. We present a retroactive study into the presence and nature of API incompatibilities between several versions of a set of Java-based software libraries; for each, we perform a detailed, manual analysis to determine what the correct adaptations are to migrate from the older to the newer version. In addition, we investigate whether any of a set of adaptation recommender techniques is capable of identifying the correct adaptations for library migration. We find that a given API incompatibility can typically be addressed by only one or two recommender techniques, but sometimes none serve. Furthermore, those techniques give correct recommendations, on average, in only about 20\% of cases.},
  Doi                      = {10.1145/2393596.2393661}
}

@MastersThesis{2008:msc:cottrell,
  Title                    = {Semi-automating Small-Scale Source Code Reuse via Structural Correspondence},
  Author                   = {Rylan Cottrell},
  School                   = {University of Calgary},
  Year                     = {2008},

  Address                  = {Calgary, Canada},
  Month                    = aug,

  Abstract                 = {Developers perform small-scale reuse tasks to save time and to increase the quality of their code, but due to their small scale, the costs of such tasks can quickly outweigh their benefits. Existing approaches focus on locating source code for reuse but do not support the integration of the located code within the developer's system, thereby leaving the developer with the burden of performing integration manually. This thesis presents an approach that uses the developer's context to help integrate the reused source code into the developer's target source code. The approach approximates a theoretical framework (higher-order anti-unification modulo theories), known to be undecidable in general, to determine candidate correspondences between the source code to be reused and the developer's current (incomplete) system. This approach has been implemented in a prototype tool, called Jigsaw, that identifies and evaluates candidate correspondences greedily with respect to the highest similarity. Situations involving multiple candidate correspondences with similarities above a defined threshold are presented to the developer for resolution. Two empirical evaluations were conducted: an experiment comparing the quality of Jigsaw's results against suspected cases of small-scale reuse in an industrial system; and case studies with two industrial developers to consider its practical usefulness and usability issues.}
}

@InProceedings{2007:esec_fse:cottrell,
  Title                    = {Determining detailed structural correspondence for generalization tasks},
  Author                   = {Rylan Cottrell and Joseph J. C. Chang and Robert J. Walker and J\"org Denzinger},
  Booktitle                = esec_fse,
  Year                     = {2007},
  Pages                    = {165--174},

  Abstract                 = {Generalization tasks are important for continual improvement to the design of an evolving code base, eliminating redundancy where it has accumulated. An important step in generalization is identifying the detailed structural correspondence between two pieces of code being considered for generalization. Unfortunately, tool support for this step is insufficient, leaving the developer to resort to tedious and error-prone manual determination of correspondence. This paper presents an approach for automatically determining correspondences as an early step in a generalization task. The approach is implemented in a proof-of-concept plug-in to the Eclipse integrated development environment. Two small empirical evaluations of the tool have been conducted: a comparison between human attempts to determine detailed correspondences and those of the tool; and, a comparison of the use of the tool to the use of diff/CCFinder in performing generalization tasks.},
  Doi                      = {10.1145/1287624.1287649}
}

@InProceedings{2009:vissoft:cottrell,
  Title                    = {Compare and contrast: Visual exploration of source code examples},
  Author                   = {Rylan Cottrell and Brina Goyette and Reid Holmes and Robert J. Walker and J\"org Denzinger},
  Booktitle                = vissoft,
  Year                     = {2009},
  Pages                    = {29--32},

  Abstract                 = {Understanding the commonalities and differences of a set of source code examples can help developers to understand or to evolve application programming interfaces (APIs). While several approaches exist to assist developers in locating source code examples, they often present their results only in a basic list view, with at most an indication of the relationship to the search query; unfortunately, they offer no information on how the results relate to one another. A developer is then faced with the highly manual task of exploring these examples to discern their similarities and differences. This paper describes our prototype tool (called Guido) for exploring source code examples, using their structural correspondences. The Guido tool uses multiple coordinated views to visualize the relationships between examples, in order to assist the developer in identifying common and unique traits between them.},
  Doi                      = {10.1109/VISSOF.2009.5336429}
}

@InProceedings{2008:fse:cottrell,
  Title                    = {Semi-automating small-scale source code reuse via structural correspondence},
  Author                   = {Rylan Cottrell and Robert J. Walker and J\"org Denzinger},
  Booktitle                = fse,
  Year                     = {2008},
  Pages                    = {214--225},

  Abstract                 = {Developers perform small-scale reuse tasks to save time and to increase the quality of their code, but due to their small scale, the costs of such tasks can quickly outweigh their benefits. Existing approaches focus on locating source code for reuse but do not support the integration of the located code within the developer's system, thereby leaving the developer with the burden of performing integration manually. This paper presents an approach that uses the developer's context to help integrate the reused source code into the developer's own source code. The approach approximates a theoretical framework (higher-order anti-unification modulo theories), known to be undecidable in general, to determine candidate correspondences between the source code to be reused and the developer's current (incomplete) system. This approach has been implemented in a prototype tool, called Jigsaw, that identifies and evaluates candidate correspondences greedily with respect to the highest similarity. Situations involving multiple candidate correspondences with similarities above a defined threshold are presented to the developer for resolution. Two empirical evaluations were conducted: an experiment comparing the quality of Jigsaw's results against suspected cases of small-scale reuse in an industrial system; and case studies with two industrial developers to consider its practical usefulness and usability issues.},
  Doi                      = {10.1145/1453101.1453130}
}

@InProceedings{2008:icse:cottrell,
  Title                    = {Jigsaw: A tool for the small-scale reuse of source code},
  Author                   = {Rylan Cottrell and Robert J. Walker and J\"{o}rg Denzinger},
  Booktitle                = icsecompanion,
  Year                     = {2008},
  Pages                    = {933--934},

  Abstract                 = {Developers perform small-scale reuse tasks to save time and to increase the quality of their code. Due to the small scale of such tasks, the overhead in reusing source code can quickly outweigh the benefits. Existing approaches focus on locating source code for reuse but do not support the integration of the located code within the developer's system, thereby leaving the developer with the burden of performing these steps manually. This paper presents a tool, called Jigsaw, that uses the developer's context to help integrate the reused source code into the developer's own source code.},
  Doi                      = {10.1145/1370175.1370194}
}

@Article{2007:sen:garcia,
  Title                    = {Assessment of contemporary modularization techniques---{ACoM'07}: Workshop report},
  Author                   = {Alessandro Garcia and Phil Greenwood and George Heineman and Robert Walker and Yuanfang Cai and Hong Yul Yang and Elisa Baniassad and Cristina Videira Lopes and Christa Schwanninger and Jianjun Zhao},
  Journal                  = sen,
  Year                     = {2007},

  Month                    = sep,
  Number                   = {5},
  Pages                    = {31--37},
  Volume                   = {32},

  Abstract                 = {The effective assessment of emerging modularization technologies plays a pivotal role on: (i) a better understanding of their real benefits and drawbacks when compared to conventional development techniques, and (ii) their effective transfer to mainstream software development. This report is intended to summarize the results of the 1st International Workshop on Assessment of Contemporary Modularization Techniques (ACoM'07) held in Minneapolis, USA, May 22, 2007, as part of the 29th International Conference on Software Engineering (ICSE'07). The main purpose of this workshop was to share and pool the collective experience of people interested in and actively working on assessment of innovative modularization techniques. The workshop consisted of an opening presentation, several paper presentations organized into three technical sessions, and four discussion groups. During the workshop presentations and discussions, the authors and participants directly and indirectly reviewed ongoing and previous work and debated a number of important issues on contemporary modularity assessment. The ACoM'07 website, including the electronic version of this report, can be found at <www.comp.lancs.ac.uk/computing/ACoM.07/>. We begin by presenting an overview of our goals and the workshop structure, and then focus on the workshop technical program and results.},
  Doi                      = {10.1145/1290993.1291005}
}

@PhdThesis{2008:phd:holmes,
  Title                    = {Pragmatic Software Reuse},
  Author                   = {Reid Holmes},
  School                   = {University of Calgary},
  Year                     = {2008},

  Address                  = {Calgary, Canada},
  Month                    = nov,

  Abstract                 = {TBD}
}

@InProceedings{2009:icsm:holmes,
  Title                    = {The end-to-end use of source code examples: An exploratory study},
  Author                   = {Reid Holmes and Rylan Cottrell and Robert J. Walker and J\"org Denzinger},
  Booktitle                = icsm,
  Year                     = {2009},
  Pages                    = {555--558},

  Abstract                 = {Source code examples are valuable to developers needing to use an unfamiliar application programming interface (API). Numerous approaches exist to help developers locate source code examples; while some of these help the developer to select the most promising examples, none help the developer to reuse the example itself. Without explicit tool support for the complete end-to-end task, the developer can waste time and energy on examples that ultimately fail to be appropriate; as a result, the overhead required to reuse an example can restrict a developer's willingness to investigate multiple examples to find the "best" one for their situation. This paper outlines four case studies involving the end-to-end use of source code examples: we investigate the overhead and pitfalls involved in combining a few state-of-the-art techniques to support the end-to-end use of source code examples.},
  Doi                      = {10.1109/ICSM.2009.5306387}
}

@TechReport{2009:tr:holmes,
  Title                    = {The end-to-end use of source code examples: An exploratory study---Appendix},
  Author                   = {Reid Holmes and Rylan Cottrell and Robert J. Walker and J\"org Denzinger},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2009},

  Address                  = {Calgary, Canada},
  Month                    = jun,
  Number                   = {2009-934-13},

  Abstract                 = {This appendix contains the details of our case studies outlined in our paper for the 2009 International Conference on Software Maintenance, as well as an expanded discussion section. The reader is directed to the main paper for introduction, motivation, and related work.},
  Doi                      = {1880/47297}
}

@InProceedings{2009:ase:holmes,
  Title                    = {Automatically recommending triage decisions for pragmatic reuse tasks},
  Author                   = {Reid Holmes and Tristan Ratchford and Martin Robillard and Robert J. Walker},
  Booktitle                = ase,
  Year                     = {2009},
  Pages                    = {397--408},

  Abstract                 = {Planning a complex software modification task imposes a high cognitive burden on developers, who must juggle navigating the software, understanding what they see with respect to their task, and deciding how their task should be performed given what they have discovered. Pragmatic reuse tasks, where source code is reused in a white-box fashion, is an example of a complex and error-prone modification task: the developer must plan out which portions of a system to reuse, extract the code, and integrate it into their own system. In this paper we present a recommendation system that automates some aspects of the planning process undertaken by developers during pragmatic reuse tasks. In a retroactive evaluation, we demonstrate that our technique was able to provide the correct recommendation 64\% of the time and was incorrect 25% of the time. Our case study suggests that developer investigative behaviour is positively influenced by the use of the recommendation system.},
  Doi                      = {10.1109/ASE.2009.65}
}

@Article{2012:tosem:holmes,
  Title                    = {Systematizing pragmatic software reuse},
  Author                   = {Reid Holmes and Robert J. Walker},
  Journal                  = tosem,
  Year                     = {2012},

  Month                    = nov,
  Number                   = {4},
  Pages                    = {20:1--20:44},
  Volume                   = {21},

  Abstract                 = {Many software reuse tasks involve reusing source code that was not designed in a manner conducive to those tasks, requiring that ad hoc modifications be applied. Such pragmatic reuse tasks are a reality in disciplined industrial practice; they arise for a variety of organizational and technical reasons. To investigate a pragmatic reuse task, a developer must navigate through, and reason about, source code dependencies in order to identify program elements that are relevant to the task and to decide how those elements should be reused. The developer must then convert his mental model of the task into a set of actions that he can perform. These steps are poorly supported by modern development tools and practices.
We provide a model for the process involved in performing a pragmatic reuse task, including the need to capture (mentally or otherwise) the developer's decisions about how each program element should be treated: this is a pragmatic-reuse plan. We provide partial support for this model via a tool suite, called Gilligan; other parts of the model are supported via standard IDE tools. Using a pragmatic-reuse plan, Gilligan can semi-automatically transform the selected source code from its originating system and integrate it into the developer's system.
We have evaluated Gilligan through a series of case studies and experiments (each involving industrial developers) using a variety of source systems and tasks; we report in particular on a previously unpublished, formal experiment. The results show that pragmatic-reuse plans are a robust metaphor for capturing pragmatic reuse intent and that, relative to standard IDE tools, Gilligan can (1) significantly decrease the time that developers require to perform pragmatic reuse tasks, (2) increase the likelihood that developers will successfully complete pragmatic reuse tasks, (3) decrease the time required by developers to identify infeasible reuse tasks, and (4) improve developers' sense of their ability to manage the risk in such tasks.},
  Doi                      = {10.1145/2377656.2377657}
}

@InProceedings{2010:icse:holmes,
  Title                    = {Customized awareness: Recommending relevant external change events},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = icse,
  Year                     = {2010},
  Pages                    = {465--474},

  Abstract                 = {It is often assumed that developers' view of their system and its environment is always consistent with everyone else's; in practice, this assumption can be false, as the developer has little practical control over changes to the environments in which their code will be deployed. To proactively respond to such situations, developers must constantly monitor a flood of information involving changes to the deployment environments; unfortunately, the vast majority of this information is irrelevant to the individual developer, and its sheer volume makes it likely that infrequent change events of relevance are overlooked. As a result, errors may arise at deployment time that the developer does not immediately detect.
This paper presents a recommendation approach for filtering the flood of change events on deployment dependencies to those that are most likely to cause problems for the individual developer. The approach is evaluated for its ability to drastically filter irrelevant details, while being unlikely to filter important ones. The relevance of the results is assessed on the basis of deployment problems that would have historically occurred within a set of industrial systems.},
  Doi                      = {10.1145/1806799.1806867}
}

@InProceedings{2009:stc:holmes,
  Title                    = {Developer-specific awareness of external changes},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = stc,
  Year                     = {2009},
  Note                     = {International Conference on Software Engineering},

  Abstract                 = {It is often assumed that developers' view of their system and its environment is always consistent with everyone else's. In certain situations that arise in practice, this assumption is false, and current development practice does not adequately address the resulting shortcomings. This paper examines when the assumption does not hold, and the implications for developers. A method for helping developers understand and cope with these situations is described and an evaluation of this method is proposed.}
}

@InProceedings{2008:chase:holmes,
  Title                    = {Promoting developer-specific awareness},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = chase,
  Year                     = {2008},
  Note                     = {International Conference on Software Engineering},
  Pages                    = {61--64},

  Abstract                 = {Maintaining a developer's awareness of changes in the software on which she depends is challenging. Awareness is often impeded at two ends of the spectrum: a lack of information, when the changes only become apparent when a build breaks or bugs appear; or an excess of information, where the changes are announced but the majority of the changes are not relevant to the developer in her particular project and context. In the middle ground lies the possibility of support for developer-specific awareness (DSA), wherein information about the changes is filtered on the basis of the developer's own code and interests. This paper discusses how the DSA problem is manifested in software development and briefly examines the design space involved in providing DSA notifications. A particular point in the space is proposed for a target implementation, called the YooHoo awareness system, that will help developers in loose organizations to keep apprised of any code changes that are specifically relevant to the source code for which they are responsible.},
  Doi                      = {10.1145/1370114.1370130}
}

@InProceedings{2008:icsr:holmes,
  Title                    = {Lightweight, semi-automated enactment of pragmatic-reuse plans},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = icsr,
  Year                     = {2008},
  Pages                    = {330--342},

  Abstract                 = {Reusing source code in a manner for which it has not been designed (which we term a pragmatic-reuse task) is traditionally regarded as poor practice. The unsystematic nature of these tasks increases the likelihood of a developer pursuing one that is infeasible or choosing not to pursue a feasible one. In previous work, we demonstrated that these risks can be mitigated by providing support to developers to help them systematically investigate and plan pragmatic-reuse tasks. But planning is only a small part of performing a pragmatic-reuse task; to enact a plan, the developer would have to manually extract the code they want to reuse and resolve any errors that arise from removing it from its originating system. This paper describes an approach that semi-automates the process of pragmatic-reuse plan enactment, automatically extracting the reused source code and resolving the majority of compilation errors for the developer through lightweight (i.e., computationally simple but analytically unsound) transformations. By reducing the number of low-level compilation issues (which are typically trivial but copious) that the developer must resolve, they are able to focus on the higher-level semantic and conceptual issues that are the main barrier to the successful completion of the reuse task. The efficacy of our approach to save developer effort is evaluated in a small-scale, controlled experiment on non-trivial pragmatic-reuse tasks. We find that our approach improves the likelihood of a pragmatic reuse task being successful, and decreases the time required to complete these tasks, as compared to a manual enactment approach.},
  Doi                      = {10.1007/978-3-540-68073-4_35}
}

@InProceedings{2008:msr:holmes,
  Title                    = {A newbie's guide to {E}clipse {API}s},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = msr,
  Year                     = {2008},
  Pages                    = {149--152},

  Abstract                 = {Eclipse has evolved from a fledgling Java IDE into a mature software ecosystem. One of the greatest benefits Eclipse provides developers is flexibility; however, this is not without cost. New Eclipse developers often find the framework to be large and confusing. Determining which parts of the framework they should be using can be a difficult task as Eclipse documentation tends to be either very high-level, focusing on the design of the framework, or low-level, focusing on specific APIs. We have developed a tool called PopCon that provides a bridge between high-level design documentation and low-level API documentation by statically analyzing a framework and several of its clients and providing a ranked list of the relative popularity of its APIs. We have applied PopCon to the Eclipse framework for this challenge to help newbie Eclipse developers identify some of the most relevant APIs for their tasks.},
  Doi                      = {10.1145/1370750.1370787}
}

@InProceedings{2007:etx:holmes,
  Title                    = {Informing {E}clipse {API} production and consumption},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = etx,
  Year                     = {2007},
  Pages                    = {70--74},

  Abstract                 = {Application programming interfaces (APIs) inform application developers as to the functionality provided by a library and how to interact with it. APIs are a double-edged sword: if they do not permit the needed functionality to be accessed and adapted as needed, they are obstructing; if they permit all things to all people, they are complex, leading application developers to have difficulty understanding how to use them correctly. Thus, the developers of APIs have a delicate balance to strike between providing configurable functionality and simple interfaces. Inevitably, the wrong balance is sometimes chosen, as the actual usage is different from the expected usage; APIs need to evolve, or to be re-documented to account for this disparity. In this paper we propose a simple technique for quantitatively determining how existing APIs are used, and demonstrate its application to Eclipse. This technique would enable application developers to more easily understand how others have used the APIs and would allow API developers to more easily understand how their APIs are being used.},
  Doi                      = {10.1145/1328279.1328294}
}

@InProceedings{2007:icse:holmes,
  Title                    = {Supporting the investigation and planning of pragmatic reuse tasks},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = icse,
  Year                     = {2007},
  Pages                    = {447--457},

  Abstract                 = {Software reuse has long been promoted as a means to increase developer productivity; however, reusing source code is difficult in practice and tends to be performed in an ad hoc manner. This is problematic because poor decisions can be made either to attempt an unwise, overly complex reuse task, or to avoid a reuse task that would have saved time and effort. This paper describes a lightweight tool that supports the investigation and planning of pragmatic reuse tasks. The tool helps developers to identify the dependencies from the source code they wish to reuse, and to decide how to deal with those dependencies. Questions about pragmatic reuse are evaluated through a survey of industrial developers. The tool is evaluated through the planning and execution of reuse tasks by industrial developers.},
  Doi                      = {10.1109/ICSE.2007.83}
}

@InProceedings{2007:vissoft:holmes,
  Title                    = {Task-specific source code dependency investigation},
  Author                   = {Reid Holmes and Robert J. Walker},
  Booktitle                = vissoft,
  Year                     = {2007},
  Pages                    = {100--107},

  Abstract                 = {We present a simple, visual approach to help developers view and navigate structural dependency information, aimed specifically at pragmatic reuse tasks. Our visual approach, implemented as the Gilligan tool, uses standard GUI widgets (such as lists and editors) that developers are familiar with. Gilligan represents complex dependency data in a simplified format, appropriate for investigating reuse tasks. We present a small-scale, semi-controlled experiment that indicates that the approach permits more accurate identification of relevant structural dependencies with a lower time investment, as compared to traditional manual approaches. Last, we discuss the potential for the approach to aid in other specific software understanding tasks.},
  Doi                      = {10.1109/VISSOF.2007.4290707}
}

@Article{2006:tse:holmes,
  Title                    = {Approximate structural context matching: An approach to recommend relevant examples},
  Author                   = {Reid Holmes and Robert J. Walker and Gail C. Murphy},
  Journal                  = tse,
  Year                     = {2006},

  Month                    = dec,
  Number                   = {12},
  Pages                    = {952--970},
  Volume                   = {32},

  Abstract                 = {When coding to an application programming interface (API), developers often encounter difficulties, unsure of which class to subclass, which objects to instantiate, and which methods to call. Example source code that demonstrates the use of the API can help developers make progress on their task. This paper describes an approach to provide such examples in which the structure of the source code that the developer is writing is matched heuristically to a repository of source code that uses the API. The structural context needed to query the repository is extracted automatically from the code, freeing the developer from learning a query language or from writing their code in a particular style. The repository is generated automatically from existing applications, avoiding the need for handcrafted examples. We demonstrate that the approach is effective, efficient, and more reliable than traditional alternatives through four empirical studies.},
  Doi                      = {10.1109/TSE.2006.117}
}

@InProceedings{2005:esec_fse:holmes,
  Title                    = {Strathcona example recommendation tool},
  Author                   = {Reid Holmes and Robert J. Walker and Gail C. Murphy},
  Booktitle                = esec_fse,
  Year                     = {2005},
  Note                     = {Research demonstration track},
  Pages                    = {237--240},

  Abstract                 = {Using the application programming interfaces (API) of large software systems requires developers to understand details about the interfaces that are often not explicitly defined. However, documentation about the API is often incomplete or out of date. Existing systems that make use of the API provide a form of implicit information on how to use that code. Manually searching through existing projects to find relevant source code is tedious and time consuming. We have created the Strathcona Example.Recommendation Tool to assist developers in finding relevant fragments of code, or examples, of an API's use. These examples can be used by developers to provide insight on how they are supposed to interact with the API.},
  Doi                      = {10.1145/1081706.1081744}
}

@MastersThesis{2010:msc:kapur,
  Title                    = {Refactoring References for Library Migration},
  Author                   = {Puneet Kapur},
  School                   = {University of Calgary},
  Year                     = {2010},

  Address                  = {Calgary, Canada},
  Month                    = may,
  Type                     = {MSc thesis},

  Abstract                 = {Dealing with change is a persistent problem that has vexed software developers and preoccupied the discipline of software engineering for more than 30 years. Changes to software can occur for a variety of reasons, and can originate from a variety of sources; developers may change their own internal source code, respond to changes in external software upon which their own software depends or introduce changes to software they write that is then reused by other software developers.
The origin of a change impacts the manner and the tools with which developers have to deal with it. When making alterations to their own source code, developers can use automated tools known as refactorings to enact changes. Existing refactorings rely on developers having access to the source code where an entity is declared and the locations where it is referenced. Refactoring tools ensure that changes to a declaration are propagated to update all the locations where that entity was referenced.
However, there exist situations in which a declaration is not available for refactoring. When creating applications that make use of external software, developers make references within their source code to entities declared by---and whose source code is managed by---someone else. When this third-party software changes, the references within the developer's own source code are broken, an outcome we refer to as dangling references.
We investigate the problem of dangling references through a detailed study of three open source libraries. We find that the introduction of dangling references during library migration is a significant real problem, and characterize the specific issues that arise. Based on these findings we provide and test a prototype tool, called Trident, that allows programmers to refactor references. Our results suggest that supporting the direct refactoring of references is a significant improvement over the state-of-the-art.}
}

@InProceedings{2010:oopsla:kapur,
  Title                    = {Refactoring references for library migration},
  Author                   = {Puneet Kapur and Brad Cossette and Robert J. Walker},
  Booktitle                = oopsla,
  Year                     = {2010},
  Pages                    = {726--738},

  Abstract                 = {Automated refactoring is a key feature of modern IDEs. Existing refactorings rely on the transformation of source code declarations, in which references may also be transformed as a side effect. However, there exist situations in which a declaration is not available for refactoring or would be inappropriate to transform, for example, in the presence of dangling references or where a set of references should be retargeted to a different declaration.
We investigate the problem of dangling references through a detailed study of three open source libraries. We find that the introduction of dangling references during library migration is a significant real problem, and characterize the specific issues that arise. Based on these findings we provide and test a prototype tool, called Trident, that allows programmers to refactor references. Our results suggest that supporting the direct refactoring of references is a significant improvement over the state-of-the-art.},
  Doi                      = {10.1145/1869459.1869518}
}

@InProceedings{2000:mdsoc:lai,
  Title                    = {Separating concerns with {Hyper/J}: An experience report},
  Author                   = {Albert Lai and Gail C. Murphy and Robert J. Walker},
  Booktitle                = mdsoc,
  Year                     = {2000},
  Note                     = {International Conference on Software Engineering},
  Pages                    = {79--91},

  Abstract                 = {In earlier work, we conducted an exploratory investigation of concerns in two existing Java packages: jFTPd and gnu.regexp. Two separate developers marked concerns in the source for each package: these concerns were then compared and analyzed. In this paper, we describe the next step of our investigations: the use of the IBM Hyper/J tool to separate and configure the identified concerns. We describe the various kinds of hyperspaces, hypermodules, hyperslices, and concern mappings we used to describe our previously identified concerns. We also discuss code restructurings we used to enable the capturing and composition of concerns.}
}

@InProceedings{1994:gi:lalonde,
  Title                    = {A model for coordinating interacting agents},
  Author                   = {Paul Lalonde and Robert Walker and Jason Harrison and David Forsey},
  Booktitle                = gi,
  Year                     = {1994},
  Pages                    = {149--156},

  Abstract                 = {SPAM (Simulated Platform for Animating Motion) is a simulation software system designed to address synchronization issues pertaining to both animation and simulation. SPAM provides application programs with the manipulation, configuration, and synchronization tools needed when simulations are combined to create animations. It is designed to be used as the glue between applications that supply lists of the parameters to animate and the callback procedures to invoke when a user wishes to modify the parameters directly. SPAM does not impose a particular model of simulation, accommodating keyframing, physical simulation, or a variety of other models, providing they can be abstracted into a set of externally modifiable values.
In SPAM we recognize that the important part of simulation is not the state of the system at each time step, but rather the change in states between steps. Thus SPAM uses an interval representation of time, explicitly representing the intervals over which change occurs.
In a complex animation or simulation, multiple actions will access the same resource at the same time. SPAM defines a strategy for recognizing such conflicts that increases the use and re-use of sequences.}
}

@MastersThesis{2006:msc:mahmud,
  Title                    = {When Should Crosscutting Concerns Be of Concern in the Software Development Lifecycle?},
  Author                   = {Shafquat Mahmud},
  School                   = {University of Calgary},
  Year                     = {2006},

  Address                  = {Calgary, Canada},
  Month                    = jul,
  Type                     = {MSc thesis},

  Abstract                 = {TBD}
}

@TechReport{2004:tr:mahmud,
  Title                    = {A Case Study in Simulated Concurrent Development and Evolution: Investigating the {T}heme Approach},
  Author                   = {Shafquat Mahmud and Robert J. Walker},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2004},

  Address                  = {Calgary, Canada},
  Month                    = oct,
  Number                   = {2004-765-30},

  Abstract                 = {AOSD aims at improving key software engineering properties (such as traceability, comprehensibility, and evolvability) through the separation and modularization of crosscutting concerns. The majority of AOSD research focuses on individual software engineering activities (such as implementation or requirements) in isolation. One exception to this trend is the Theme approach of Clarke and colleagues, which considers the derivation of implementations from requirements through design. Evidence is currently meagre for or against the claims of this approach. This paper describes a case study involving the development and evolution of a benchmark system to evaluate these claims. Alternative decisions are examined to consider whether one or more feasible development processes exist in applying Theme. Lessons learned from the study are discussed for their generalizability to other scenarios.},
  Doi                      = {1880/46087}
}

@Article{2013:spe:makady,
  Title                    = {Validating pragmatic reuse tasks by leveraging existing test suites},
  Author                   = {Soha Makady and Robert J. Walker},
  Journal                  = spe,
  Year                     = {2013},

  Month                    = sep,
  Number                   = {9},
  Pages                    = {1039--1070},
  Volume                   = {43},

  Abstract                 = {Traditional industrial practice often involves the ad hoc reuse of source code that was not designed for that reuse. Such pragmatic reuse tasks play an important role in disciplined software development. Pragmatic reuse has been seen as problematic due to a lack of systematic support, and an inability to validate that the reused code continues to operate correctly within the target system. Although recent work has successfully systematized support for pragmatic reuse tasks, the issue of validation remains unaddressed. In this paper, we present a novel approach and tool to semi-automatically reuse and transform relevant portions of the test suite associated with pragmatically reused code, as a means to validate that the relevant constraints from the originating system continue to hold, while minimizing the burden on the developer. We conduct a formal experiment with experienced developers, to compare the application of our approach versus the use of a standard IDE (the `manual approach'). We find that, relative to the manual approach, our approach: reduces task completion time; improves instruction coverage by the reused test cases; and improves the correctness of the reused test cases.},
  Doi                      = {10.1002/spe.2134}
}

@InProceedings{2007:ase:mcintyre,
  Title                    = {Assisting potentially-repetitive small-scale changes via semi-automated heuristic search},
  Author                   = {Mark McIntyre and Robert J. Walker},
  Booktitle                = ase,
  Year                     = {2007},
  Pages                    = {497--500},

  Abstract                 = {When a software system undergoes modification, a given change might need to be repeated throughout the codebase. While the change itself may not be difficult to implement, discovering other locations where this change should be applied (if any exist) can be onerous. Syntactic differences in otherwise semantically similar code can render traditional search techniques ineffective. This paper describes a heuristic search technique to help find the locations required to complete a repetitive small-scale change (RSC). By observing the developer perform a change once, it is possible to infer semantic information about that change and to automatically suggest locations where the same change ought to be made.},
  Doi                      = {10.1145/1321631.1321718}
}

@MastersThesis{2007:msc:mcintyre,
  Title                    = {Supporting Repetitive Small-Scale Changes},
  Author                   = {Mark M. McIntyre},
  School                   = {University of Calgary},
  Year                     = {2007},

  Address                  = {Calgary, Canada},
  Month                    = sep,
  Type                     = {MSc thesis},

  Abstract                 = {TBD}
}

@InProceedings{2001:icse:murphy,
  Title                    = {Separating features in source code: An exploratory study},
  Author                   = {Gail C. Murphy and Albert Lai and Robert J. Walker and Martin P. Robillard},
  Booktitle                = icse,
  Year                     = {2001},
  Pages                    = {275--284},

  Abstract                 = {Most software systems are inflexible. Reconfiguring a system's modules to add or to delete a feature requires substantial effort. This inflexibility increases the costs of building variants of a system, amongst other problems. New languages and tools that are being developed to provide additional support for separating concerns show promise to help address this problem. However applying these mechanisms requires determining how to enable a feature to be separated from the codebase. We investigate this problem through an exploratory study conducted in the context of two existing systems: gnu.regexp and jFTPd. The study consisted of applying three different separation of concern mechanisms: Hyper/J, AspectJ and a lightweight, lexically-based approach, to separate features in the two packages. We report on the study, providing contributions in two areas. First, we characterize the effect different mechanisms had on the structure of the codebase. Second, we characterize the restructuring process required to perform the separations. These characterizations can help researchers to elucidate how the mechanisms may be best used, tool developers to design support to aid the separation process, and early adopters to apply the techniques.},
  Doi                      = {10.1109/ICSE.2001.919101}
}

@Article{1999:tse:murphy,
  Title                    = {Evaluating emerging software development technologies: Lessons learned from assessing aspect-oriented programming},
  Author                   = {Gail C. Murphy and Robert J. Walker and Elisa L. A. Baniassad},
  Journal                  = tse,
  Year                     = {1999},

  Month                    = jul # {/} # aug,
  Note                     = {Special Section on Empirical Software Engineering},
  Number                   = {4},
  Pages                    = {438--455},
  Volume                   = {25},

  Abstract                 = {Determining whether a new software development technique is useful and usable is a challenging taste. Various flavors of empirical study may be used to help with this task, including surveys, case studies, and experiments. Little guidance is available within the software engineering community to help choose among these alternatives when assessing a new and evolving software development technique within some cost bounds. We faced this challenge when assessing a new programming technique called aspect-oriented programming. To assess the technique, we chose to apply both a case study approach and a series of four experiments because we wanted to understand and characterize the kinds of information that each approach might provide. We describe and critique the evaluation methods we employed, and discuss the lessons we have learned. These lessons are applicable to other researchers attempting to assess new programming techniques that are in an early stage of development.},
  Doi                      = {10.1109/32.799936}
}

@TechReport{1998:tr:murphy,
  Title                    = {Evaluating Emerging Software Development Technologies: Lessons Learned from Assessing Aspect-oriented Programming},
  Author                   = {Gail C. Murphy and Robert J. Walker and Elisa L. A. Baniassad},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {1998},

  Address                  = {Vancouver, Canada},
  Month                    = jul,
  Number                   = {TR-98-10},

  Abstract                 = {Two of the most important and most difficult questions one can ask about a new software development technique are whether the technique is useful and whether the technique is usable. Various flavours of empirical study are available to evaluate these questions, including surveys, case studies, and experiments. These different approaches have been used extensively in a number of domains, including management science and human-computer interaction. A growing number of software engineering researchers are using experimental methods to statistically validate hypotheses about relatively mature software development aids. Less guidance is available for a developer of a new and evolving software development technique who is attempting to determine, within some cost bounds, if the technique shows some usefulness. We faced this challenge when assessing a new programming technique called aspect-oriented programming. To assess the technique, we chose to apply both a case study approach and a series of four experiments because we wanted to understand and characterize the kinds of information that each approach might provide when studying a technique that is in its infancy. Our experiences suggest some avenues for further developing empirical methods aimed at evaluating software engineering questions. For instance, guidelines on how different observational techniques can be used as multiple sources of data would be helpful when planning and conducting a case study. For the experimental situation, more guidance is needed on how to balance the precision of measurement with the realism necessary to investigate programming issues. In this paper, we describe and critique the evaluation methods we employed, and discuss the lessons we have learned. These lessons are applicable to researchers attempting to assess other new programming techniques that are in an early stage of development. },
  Url                      = {http://www.cs.ubc.ca/cgi-bin/tr/1998/TR-98-10.pdf}
}

@Article{2001:cacm:murphy,
  Title                    = {Does aspect-oriented programming work?},
  Author                   = {Gail C. Murphy and Robert J. Walker and Elisa L. A. Baniassad and Martin P. Robillard and Albert Lai and Mik A. Kersten},
  Journal                  = cacm,
  Year                     = {2001},

  Month                    = oct,
  Note                     = {Special Issue on Aspect-Oriented Programming},
  Number                   = {10},
  Pages                    = {75--77},
  Volume                   = {44},

  Abstract                 = {Wouldn't it be great to know in advance that the use of aspect-oriented programming (AOP) for your next project would be successful? Unfortunately, developers and managers seldom have access to evidence assuring them that the benefits promised by a new technology, such as AOP, will be achieved if they adopt the technology. Instead, they must take a ``leap of faith", believing that the technology will help them overcome problems encountered previously. To thoroughly evaluate the usefulness of AOP, multiple software development organizations would need to build their products both with and without AOP followed by a comparison of the results. Such an approach is unrealistic. Is the situation then hopeless? Can software engineering researchers provide any help to determine if it is beneficial for software development organizations to adopt AOP for building their software products? We believe researchers can provide help and we have undertaken a number of studies using a variety of techniques to assess the usefulness of AOP and similar technologies.},
  Doi                      = {10.1145/383845.383862}
}

@PhdThesis{2014:phd:nurolahzade,
  Title                    = {Improving the Selection of Semantically Relevant Code},
  Author                   = {Nurolahzade, Mehrdad},
  School                   = {University of Calgary},
  Year                     = {2014},

  Owner                    = {walker},
  Timestamp                = {2014.12.11}
}

@InProceedings{2013:icsr:nurolahzade,
  Title                    = {An assessment of test-driven reuse: Pitfalls and promises},
  Author                   = {Mehrdad Nurolahzade and Robert J. Walker and Frank Maurer},
  Booktitle                = icsr,
  Year                     = {2013},
  Pages                    = {65--80},
  Series                   = lncs,
  Volume                   = {7925},

  Abstract                 = {Test-driven reuse (TDR) proposes to find reusable source code through the provision of test cases describing the functionality of interest to a developer. Proponents claim that their TDR approaches work well. This paper presents the results of an experiment to evaluate the ability of state-of-the-art TDR tools to locate reusable source code for realistic tasks. We find that non-trivial functionality, like that needed in the daily tasks of developers, can largely not be retrieved by these approaches. We provide an analysis of the shortcomings and underlying problems in the existing approaches, and a discussion of potential solutions.},
  Doi                      = {10.1007/978-3-642-38977-1_5}
}

@InProceedings{2011:chase:phillips,
  Title                    = {Branching and merging: An investigation into current version control practices},
  Author                   = {Shaun Phillips and Jonathan Sillito and Rob Walker},
  Booktitle                = chase,
  Year                     = {2011},
  Note                     = {ACM/IEEE International Conference on Software Engineering},
  Pages                    = {9--15},

  Abstract                 = {The use of version control has become ubiquitous in software development projects. Version control systems facilitate parallel development and maintenance through branching, the creation of isolated codelines. Merging is a consequence of branching and is the process of integrating codelines. However, there are unanswered questions about the use of version control to support parallel development; in particular, how are branching and merging used in practice? What defines a successful branching and merging strategy? As a first step towards answering these questions, we recruited a diverse sample of 140 version control users to participate in an online survey. In this paper, we present the survey results and 4 key observations about branching and merging practices in software development projects.},
  Doi                      = {10.1145/1984642.1984645}
}

@MastersThesis{2009:msc:rawal,
  Title                    = {Using Method Similarity over Versions to Improve Predictions Based on Change History},
  Author                   = {Bhavya Rawal},
  School                   = {University of Calgary},
  Year                     = {2009},

  Address                  = {Calgary, Canada},
  Month                    = aug,
  Type                     = {MSc thesis},

  Abstract                 = {Software developers are often required to perform modification tasks that involve source code spanning multiple files. To assist developers in finding relevant source code when working on a modification task, current approaches make use of data mining techniques to identify change patterns. These change patterns are mined from the version history of a system and are used to identify co-changing entities of potential interest.
These current approaches rely on the name and location of the source code entity to identify that entity and to associate history with it. Using name and location for entity identification leads to loss of historical information for entities that have undergone any transformations that have modified their name or location. Such transformations occur during common maintenance practice (like refactoring) and are fairly commonplace in evolving systems.
In our work we have focused on associating history with transformed code entities to improve mining-based recommender systems. We have used various method facts to identify similarity between methods in different versions. Historical information from highly similar entities is used to estimate the historical information that is missing from transformed entities. We hypothesize that predictions utilizing this similarity-derived historical information can provide higher number of pertinent recommendations over techniques that would not estimate the missing information.
To test our hypothesis, we have extended the existing change history based approach of Ying et al. and compared the results of our extension with the original approach.}
}

@Article{2010:software:robillard,
  Title                    = {Recommendation systems for software engineering},
  Author                   = {Martin Robillard and Robert Walker and Thomas Zimmermann},
  Journal                  = software,
  Year                     = {2010},

  Month                    = jul # {/} # aug,
  Number                   = {4},
  Pages                    = {80--86},
  Volume                   = {27},

  Abstract                 = {Software development can be challenging because of the large information spaces that developers must navigate. Without assistance, developers can become bogged down and spend a disproportionate amount of their time seeking information at the expense of other value-producing tasks. Recommendation systems for software engineering (RSSEs) are software tools that can assist developers with a wide range of activities, from reusing code to writing effective bug reports. The authors provide an overview of recommendation systems for software engineering: what they are, what they can do for developers, and what they might do in the future.},
  Doi                      = {10.1109/MS.2009.161}
}

@MastersThesis{2011:msc:sadi,
  Title                    = {Characterization of the Usage of Logging Functionality via Pattern Inference},
  Author                   = {Iftekhar Amin Sadi},
  School                   = {University of Calgary},
  Year                     = {2011},

  Address                  = {Calgary, Canada},
  Month                    = jun,
  Type                     = {MSc thesis},

  Abstract                 = {Logging is used for representing state of a system in a human readable way. If properly done, logging provides valuable information for system maintenance. However, badly produced logging can be an extra overhead on resources and confusing for end users. Researchers and practitioners have often considered logging to be trivial. But a close inspection of logging proves that in real world applications it is not that simple. In this thesis we have defined some guiding principles to characterize usage of logging functionality. Based on these principles we tried to characterize logging functionality usage using an aspect-orietned programming language. When that approach failed due to limitations of the aspect-oriented programming language, we tried to characterize logging functionality usage using anti-unification. Anti-unification provides a formal model for generalizing structure, which we used to come up with a set of generalized patterns to charaterize logging functionality usage. This approach has been implemented as a prototype tool, that extracts pattern from source code and generalizes them over multiple iteration. An empirical study was conducted to determine the efficacy of the approach.}
}

@InProceedings{2006:aosd:siadat,
  Title                    = {Optimization aspects in network simulation},
  Author                   = {Jamal Siadat and Robert J. Walker and Cameron Kiddle},
  Booktitle                = aosd,
  Year                     = {2006},
  Pages                    = {122--133},

  Abstract                 = {A primary goal of AOSD in the context of systems software has been to permit improved modularity without significantly degrading performance. Optimizations represent important crosscutting concerns in this context but also a significant challenge due to their fine-grained nature. This paper investigates how well the current state-of-the-art in AOSD can support such optimization aspects, via a case study involving an optimized network simulator, IP-TN. Duplication of optimizations achieved via low-level modifications to IP-TN in C++ have been attempted via aspectization of those optimizations in AspectC++. While comparable run-time performance is achieved with AspectC++ and (un)pluggability is clearly simpler, the effects on comprehensibility are less clear.},
  Doi                      = {10.1145/1119655.1119673}
}

@TechReport{2005:tr:siadat,
  Title                    = {Optimization Aspects in Network Simulation},
  Author                   = {Jamal Siadat and Robert J. Walker and Cameron Kiddle},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2005},

  Address                  = {Calgary, Canada},
  Month                    = sep,
  Number                   = {2005-802-33},

  Abstract                 = {A primary goal of AOSD in the context of systems software has been to permit improved modularity without significantly degrading performance. Optimizations represent important crosscutting concerns in this context but also a significant challenge due to their fine-grained nature. This paper investigates how well the current state-of-the-art in AOSD can support such optimization aspects, via a case study involving an optimized network simulator, IP-TN. Duplication of optimizations achieved via low-level modifications to IP-TN in C++ have been attempted via aspectization of those optimizations in AspectC++. While comparable run-time performance is achieved with AspectC++ and (un)pluggability is clearly simpler, the effects on comprehensibility are less clear.},
  Doi                      = {1880/46088}
}

@MastersThesis{2006:msc:siadat,
  Title                    = {An Evaluation of Simultaneous Evolvability and Efficiency in Aspect-Oriented Software Development},
  Author                   = {S. Jamal A. Siadat},
  School                   = {University of Calgary},
  Year                     = {2006},

  Address                  = {Calgary, Canada},
  Month                    = dec,
  Type                     = {MSc thesis},

  Abstract                 = {TBD}
}

@PhdThesis{2012:phd:taube-schock,
  Title                    = {Patterns of Change: Can Modifiable Software Have High Coupling?},
  Author                   = {Craig Taube-Schock},
  School                   = {University of Waikato},
  Year                     = {2012},

  Address                  = {Hamilton, New Zealand},
  Month                    = may,

  Abstract                 = {There are few aspects of modern life that remain unaffected by software, and as our day-to-day challenges change, so too must our software. Software systems are complex, and as they grow larger and more interconnected, they become more difficult to modify due to excessive change propagation. This is known as the ripple effect. The primary strategies to mitigate it are modular design, and minimization of coupling, or between-module interaction. However, analysis of complex networks has shown that many are scale-free, which means that they contain some components that are highly connected. The presence of scale-free structure implies high coupling, which suggests that software systems may be hard to modify because they suffer from the ripple effect.
In this thesis, a large corpus of open-source software systems is analyzed to determine whether software systems are scale-free, whether scale-free structure results in high coupling, and whether high coupling results in ripple effects that propagate change to a large proportion of classes.
The results show that all systems in the corpus are scale-free and that that property results in high coupling. However, analysis of system evolution reveals that existing code is modified infrequently and that there is rarely sufficient evidence to be confident that ripple effects involving a high proportion of classes have actually occurred. This thesis concludes first that while it is desirable to avoid excessive interconnectivity, it is difficult to completely eliminate high coupling; and second, that the presence of high coupling does not necessarily imply poor system design.},
  Doi                      = {10289/6373}
}

@InProceedings{2011:ecoop:taube-schock,
  Title                    = {Can we avoid high coupling?},
  Author                   = {Craig Taube-Schock and Robert J. Walker and Ian H. Witten},
  Booktitle                = ecoop,
  Year                     = {2011},
  Pages                    = {204--228},
  Series                   = lncs,
  Volume                   = {6813},

  Abstract                 = {It is considered good software design practice to organize source code into modules and to favour within-module connections (cohesion) over between-module connections (coupling), leading to the oftrepeated maxim ``low coupling/high cohesion". Prior research into network theory and its application to software systems has found evidence that many important properties in real software systems exhibit approximately scale-free structure, including coupling; researchers have claimed that such scale-free structures are ubiquitous. This implies that high coupling must be unavoidable, statistically speaking, apparently contradicting standard ideas about software structure. We present a model that leads to the simple predictions that approximately scale-free structures ought to arise both for between-module connectivity and overall connectivity, and not as the result of poor design or optimization shortcuts. These predictions are borne out by our large-scale empirical study. Hence we conclude that high coupling is not avoidable---and that this is in fact quite reasonable.},
  Doi                      = {10.1007/978-3-642-22655-7_10}
}

@MastersThesis{2005:msc:viggers,
  Title                    = {Improving the Modularity of Context-Sensitive Concerns through the Use of Declarative Event Patterns},
  Author                   = {Kevin Viggers},
  School                   = {University of Calgary},
  Year                     = {2005},

  Address                  = {Calgary, Canada},
  Month                    = sep,
  Type                     = {MSc thesis},

  Abstract                 = {TBD}
}

@TechReport{2004:tr:viggers,
  Title                    = {An Implementation of Declarative Event Patterns},
  Author                   = {Kevin Viggers and Robert J. Walker},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2004},

  Address                  = {Calgary, Canada},
  Month                    = dec,
  Number                   = {2004-745-10},

  Abstract                 = {Characterizing patterns of events that occur during the execution of a software system and how the program should respond to such patterns is an important and a natural way to think about stateful crosscutting concerns. Our work on declarative event patterns (DEPs) has lead to the development of a language that allows for patterns in a program's execution to be expressed as context-free patterns of events, and for the occurrences of these patterns to alter the course of the program's execution. As a companion to a conference paper introducing DEPs, this technical report covers an initial realization of our declarative event pattern language that leverages the power and applicability of aspect-oriented programming (AOP). We have added to AspectJ (a popular Java implementation of AOP) two straight forward language constructs to support the recognition of patterns of events. Our proof-ofconcept implementation takes programs implemented in AspectJ augmented with our DEP constructs and translates them into programs implemented in standard AspectJ, equipped to recognize and respond to patterns of events as they occur in the execution of the system.},
  Doi                      = {1880/46085}
}

@InProceedings{1997:skigraph:walker,
  Title                    = {Information engineering on the {World-Wide Web}: Drawing analogies with software engineering},
  Author                   = {Rob Walker},
  Booktitle                = skigraph,
  Year                     = {1997},
  Pages                    = {97--107},

  Abstract                 = {The advent of the World-Wide Web as a distributed hypermedia database is forcing a departure from the traditional views of static, published information. The perception that the information here is easily alterable is creating, and will continue to create, the demand for continual change to this information. However, many issues such as maintaining visible structure for navigability and revision, versioning, and restructuring are causing this perception to be unfounded, particularly as the amount of information necessary to maintain increases. We draw on the experiences and observations gained in the field of software engineering to show us some solutions and limitations to these problems which are being encountered now, and which we believe must get worse.}
}

@InProceedings{2013:iea_aie:walker,
  Title                    = {Recent advances in recommendation systems for software engineering},
  Author                   = {Robert J. Walker},
  Booktitle                = iea_aie,
  Year                     = {2013},
  Pages                    = {372--381},
  Series                   = lncs,
  Volume                   = {7906},

  Abstract                 = {Software engineers must contend with situations in which they are exposed to an excess of information, cannot readily express the kinds of information they need, or must make decisions where computation of the unequivocally correct answer is infeasible. Recommendation systems have the potential to assist in such cases. This paper overviews some recent developments in recommendation systems for software engineering, and points out their similarities to and differences from more typical, commercial applications of recommendation systems. The paper focuses in particular on the problem of software reuse, and speculates why the recently cancelled Google Code Search project was doomed to failure as a general purpose tool.},
  Doi                      = {10.1007/978-3-642-38577-3_38}
}

@InProceedings{2007:acom:walker,
  Title                    = {Performing and reviewing assessments of contemporary modularization approaches: What constitutes reasonable expectations?},
  Author                   = {Robert J. Walker},
  Booktitle                = acom,
  Year                     = {2007},
  Note                     = {International Conference on Software Engineering},

  Abstract                 = {The inherent difficulties in assessing contemporary modularization (CoM) approaches are considered. The motivation is provided for a model relating assessment methodologies to the maturity of the CoM approach.},
  Doi                      = {10.1109/ACOM.2007.8}
}

@TechReport{2004:tr:walker:b,
  Title                    = {{IConJ} 0.1: A Proof-of-Concept Tool for the Application of the Implicit Context Model to {J}ava Software},
  Author                   = {Robert J. Walker},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2004},

  Address                  = {Calgary, Canada},
  Month                    = aug,
  Number                   = {2004-757-22},

  Abstract                 = {Implicit context is a model for the generative adaptation of software modules that can be declaratively incomplete or inconsistent with other modules in a system. This technical report describes the syntax and semantics of a proof-of-concept tool (IConJ 0.1) for the application of the implicit context model to software written in the Java language.},
  Doi                      = {1880/46086}
}

@PhdThesis{2003:phd:walker,
  Title                    = {Essential Software Structure through Implicit Context},
  Author                   = {Robert James Walker},
  School                   = {University of British Columbia},
  Year                     = {2003},

  Address                  = {Vancouver, Canada},
  Month                    = mar,

  Abstract                 = {Software reuse and evolution are problematic. Modules tend to express a great deal of knowledge about the external modules, large-scale structure, and behaviour of the systems in which they reside. As a result, the reusability of individual modules is decreased as they are too dependent on other modules. Likewise, the evolvability of systems is decreased as they are too dependent on the details of individual modules. However, we must have some dependences between our modules, or they would not be able to operate together. Not all dependences are equally bad, then. Each module can be seen to have a minimal core, an essential structure, beyond which it makes no sense to reduce. This essential structure describes the basic responsibilities of that module, and its expectations of the responsibilities of external modules. The thesis of this dissertation is that expressing the essential structure of our software modules, through the use of implicit context, makes those modules easier to reuse and the systems containing those modules easier to evolve. Implicit context revolves around the notion that we must abandon the need for all modules to be defined with respect to an absolute frame of reference. Instead, modules can be defined relative to a reference frame of convenience. In order for modules to work together, the inconsistencies in their independent world views must be reconciled when they attempt to communicate. Implicit context provides the novel mechanism of contextual dispatch to perform this reconciliation. When any communication passes into or out of a module, that communication may be rerouted, altered, replaced, or discarded altogether, as the situation dictates. This translation process sometimes requires access to information about the communication history of the system; objects previously passed can be retrieved, or the appropriate recipient of a message can be determined. The dissertation describes a prototype tool that supports the application of implicit context to Java source code. The thesis is validated by applying this tool in two case studies: comparing the evolution of an implicit context-based implementation of an FTP server to an object-oriented implementation; and reusing the Outline View of the Eclipse integrated development environment in a different application, even though the Outline View was not designed for such reuse.},
  Doi                      = {2429/14909}
}

@InProceedings{2003:splat:walker,
  Title                    = {Supporting inconsistent world views},
  Author                   = {Robert J. Walker},
  Booktitle                = splat,
  Year                     = {2003},
  Note                     = {International Conference on Aspect-Oriented Software Development},
  Pages                    = {14:1--14:5},

  Abstract                 = {When composing components that have been independently developed, coordinated pre-planning to ensure interoperability is not always an option. Without pre-planning, mismatches in architectures, interfaces, or protocols tend to occur that prevent the composition of components. To enable the composition of mismatched components, components must be permitted to possess inconsistent world views on the constituents of a system, their interfaces, and protocols. At composition time, the conflicts in these world views are reconciled. Each component can express only those details about the system that are important for its local operation. As a result, a component can interact with its context of operation while remaining oblivious to the concrete details there. This position paper outlines how a technique called implicit context can be used to support and reconcile inconsistent world views. No other existing AOP approaches are capable of this.},
  Url                      = {http://www.daimi.au.dk/~eernst/splat03/papers/Robert_Walker.pdf}
}

@TechReport{2000:tr:walker:a,
  Title                    = {Eliminating Cycles in Composed Class Hierarchies},
  Author                   = {Robert J. Walker},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {2000},

  Address                  = {Vancouver, Canada},
  Month                    = jul,
  Number                   = {TR-2000-07},

  Abstract                 = {Multiple class hierarchies can be used each to represent a separate requirement or design concern. To yield a working system, these disparate hierarchies must be composed in a semantically meaningful way. However, cycles can arise in the composed inheritance graph that restrict the space of composable hierarchies. This work presents an approach to eliminating these cycles by means of separating the type hierarchy from the implementation hierarchy; separate solutions are provided for languages permitting multiple inheritance, such as C++, and those permitting only interfaces, such as Java. The resulting acyclic class hierarchy will maintain the significant constraints imposed by the original, separate hierarchies, such as type-safety.}
}

@InProceedings{1999:icse:walker:b,
  Title                    = {Contextual programming},
  Author                   = {Robert J. Walker},
  Booktitle                = icse,
  Year                     = {1999},
  Note                     = {Doctoral symposium},
  Pages                    = {734--735},

  Abstract                 = {When information external to a component is of no importance to the implementation of that component, but is present within it as an artifact of design or programming mechanisms, system structure suffers, resulting in greater difficulties in software evolution and reuse. I am investigating an approach to lessening the effects of such extraneous embedded knowledge through the use of dynamic execution information and static structural information, which comprise the concept of context.},
  Doi                      = {10.1145/302405.303004}
}

@MastersThesis{1996:msc:walker,
  Title                    = {Integrating Simulation and Animation Software Systems through a Generic Computational Engine},
  Author                   = {Robert James Walker},
  School                   = {University of British Columbia},
  Year                     = {1996},

  Address                  = {Vancouver, Canada},
  Month                    = nov,

  Abstract                 = {There continue to be a proliferation of simulation/animation software packages. These packages typically are not designed to communicate in a general fashion with others, or if they do, often require tight restrictions on the conceptual designs of their partners typically in terms of temporal management. Attempting to combine and coordinate such disparate packages leads to the requirement of a system for the manipulation, configuration, and synchronization of communication between them. The form of such a communication system is naturally described in terms of a graph; thus, the need for a means to utilize some sort of graph or network as a computational engine arises. A particular formulation of coloured Petri nets (CPNs) is seen to be an effective vehicle to this end; in addition, a system built out of CPNs has the ability to be directly analyzed, since that is what CPNs were originally devised for. This work demonstrates an efficient implementation method which also leads to additional, desirable features such as permitting a hierarchical construction language.},
  Doi                      = {2429/6064}
}

@MastersThesis{1994:bsc:walker,
  Title                    = {{SPAM} Prototype Implementation},
  Author                   = {Robert James Walker},
  School                   = {Department of Computer Science, University of British Columbia},
  Year                     = {1994},

  Address                  = {Vancouver, Canada},
  Month                    = jun,
  Type                     = {BSc thesis},

  Abstract                 = {The design concepts underlying this prototype implementation are as discussed in [lalo94]. Some of the terminology of the final draft of that paper has not yet been fully adhered to: it was felt that obtaining a fully functional system was of paramount importance, especially as the alterations necessary for full compliance are more superficial in nature than functional yet sufficiently detailed that it would be best to wait and add them to a confidently debugged system. These departures will be noted where they occur and the necessary alterations given. Also noted are suggested alterations to the system for future implementations and additional or outstanding topics requiring further study.
The source code for the system was written in ANSI C as described by [kern88]. The red-black trees and interval trees used in the system are based upon the pseudocode given by [corm90]; the red-black trees were altered so as to key upon arbitrary data structures given a comparison subroutine. Simplifying assumptions were used in the interval trees which are discussed in the Steward Caches section.}
}

@InCollection{2004:book:filman:walker,
  Title                    = {An initial assessment of aspect-oriented programming},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Booktitle                = {Aspect-Oriented Software Development},
  Publisher                = {Addison-Wesley},
  Year                     = {2004},
  Chapter                  = {23},
  Editor                   = {Robert E. Filman and Tzilla Elrad and Siobh\'an Clarke and Mehmet Ak{\c{s}}it},

  Abstract                 = {The principle of separation of concerns [6] has long been used by software engineers to manage the complexity of software system development. Many programming languages provide explicit support for separation of concerns by providing different sub-languages for expressing the structure of data versus the functionality to be performed on the data. Pascal [10] is one example of a language with this design. Software specifiers and designers also use the principle when using notations, such as UML [18], which place structural and functional information into separate diagrams.
Aspect-oriented programming is a new programming technique that takes another step towards increasing the kinds of design concerns that can be captured cleanly within source code [11]. Aspect-oriented programming provides explicit language support for modularizing design decisions that crosscut a functionallydecomposed program. Instead of spreading the code related to a design decision throughout a program's source, a developer is able to express the decision within a separate, coherent piece of code. For example, ensuring that a set of operations do not execute concurrently typically requires spreading code throughout the operations; an aspect-oriented approach allows the synchronization constraint to be specified in one separate piece of code. The aspect code is combined with the primary program code by an aspect weaver. Several different aspect-oriented programming systems have been built, including AML [9], an environment for sparse matrix computation, and RG [16], an environment for creating image processing systems.
The aspect-oriented approach claims to make it easier to reason about, develop, and maintain certain kinds of application code [11]. To begin assessing these claims, we undertook a series of exploratory qualitative studies, including both case studies and experiments [17]. The case study format allowed us to investigate broad usefulness and usability questions surrounding the approach. The experiment format allowed us to focus on more specific questions related to the claim of the technique.
This paper reports on two of the exploratory experiments we conducted to investigate aspect-oriented programming. A particular aspect-oriented programming language created by researchers at Xerox PARC, called AspectJ [1], was used in these studies. This version of AspectJ uses a slightly modified form of Java [7] for expressing the core functionality of a program, and supports two aspect languages: Cool for expressing synchronization concerns, and Ridl for expressing distribution concerns.
Each of the two experiments considered a different programming activity. In the first experiment, we considered whether the separation of concerns provided by AspectJ enhanced a developer's ability to find and fix faults present in a multithreaded program. The second experiment focused on the ease of changing an existing distributed system. In each case, we compared the performance and experience of programmers working in AspectJ with those of programmers working in a control language: Java in the case of the debugging experiment, and Emerald [3] in the case of the change experiment.
The results of these experiments highlight the importance of the aspect–core interface in achieving development benefits with aspect-oriented programming. The aspect–core interface refers to the boundary between code expressed as an aspect and the functionally-decomposed code. This interface is narrow when the scope of the effect of an aspect across the boundary is well-defined, and when the aspect can be reasoned about without extensive analysis of the core code. In the experiments, the narrow interface provided by the synchronization aspect language helped the participants to complete assigned tasks. In contrast, the wider interface provided by the distribution concern language seemed to hinder participants.
Our experiments also indicate that aspect-oriented programming may alter the programming strategies used by developers. Specifically, programmers may be more likely to first try to solve a problem related to a concern captured as an aspect by initially focusing on the aspect code. This new strategy tends to help when the programmer's hunch that the problem is pertinent to the concern is correct, and when the aspect cleanly captures the concern. When these conditions do not hold, this strategy may lead to a drop in programmer performance.
Although gathered at an early stage in the evolution of aspect-oriented programming, these empirical results can help evolve the approach in several ways. First, the results can help builders of cross-cutting modularity techniques, such as aspectoriented programming and the closely related subject-oriented programming [8], improve the usefulness and usability of the techniques. The results can also help bridge to another useful form of empirical study—longer running industrial-based case studies—by helping potential early adopters of the technology determine whether the technique is suitable to address some of their development problems. Finally, software engineering researchers may build on our methods and results to continue experimental studies of both aspect-oriented programming and other separation of concern techniques.}
}

@InProceedings{1999:icse:walker:a,
  Title                    = {An initial assessment of aspect-oriented programming},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Booktitle                = icse,
  Year                     = {1999},
  Pages                    = {120--130},

  Abstract                 = {The principle of separation of concerns (E. Dijkstra, 1976) has long been used by software engineers to manage the complexity of software system development. Programming languages help software engineers explicitly maintain the separation of some concerns in code. As another step towards increasing the scope of concerns that can be captured cleanly within the code, G. Kiczales et al. (1997) have introduced aspect oriented programming. In aspect oriented programming, explicit language support is provided to help modularize design decisions that cross-cut a functionally decomposed program. Aspect oriented programming is intended to make it easier to reason about, develop, and maintain certain kinds of application code. To investigate these claims, we conducted two exploratory experiments that considered the impact of aspect oriented programming, as found in AspectJ version 0.1, on two common programming activities: debugging and change. Our experimental results provide insights into the usefulness and usability of aspect oriented programming. Our results also raise questions about the characteristics of the interface between aspects and functionally decomposed core code that are necessary to accrue programming benefits. Most notably, the separation provided by aspect oriented programming seems most helpful when the interface is narrow (i.e., the separation is more complete); partial separation does not necessarily provide partial benefit.},
  Doi                      = {10.1145/302405.302458}
}

@InProceedings{1998:aop:walker,
  Title                    = {Assessing aspect-oriented programming and design: Preliminary Results},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Booktitle                = aop,
  Year                     = {1998},
  Note                     = {International Conference on Software Engineering},

  Abstract                 = {Aspect-oriented programming is a new software design and implementation technique proposed by researchers at Xerox PARC. This project is assessing the claims of aspect-oriented programming to improve the software development cycle for particular kinds of applications. The project is divided into three experiments, the first of which has been completed. These experiments have been designed to investigate, separately, such characteristics of aspect-oriented development as the creation of new aspect-oriented programs and ease of debugging aspect-oriented programs.}
}

@InProceedings{1998:ecoopw:walker,
  Title                    = {Assessing aspect-oriented programming and design: Preliminary results},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Booktitle                = eccopw,
  Year                     = {1998},
  Pages                    = {433--434},
  Series                   = lncs,
  Volume                   = {1543},

  Abstract                 = {The aspect-oriented programming approach claims to make it easier to reason about, develop, and maintain certain kinds of application code while maintaining highly efficient code. To better understand the usefulness and usability of the aspect-oriented approach, we have been conducting a series of experiments. These experiments are designed to investigate such characteristics of aspect-oriented development as the creation and ease of debugging programs built in this style. This paper provides an overview of the experiments we have conducted to date.},
  Doi                      = {10.1007/3-540-49255-0_131}
}

@TechReport{1998:tr:walker:a,
  Title                    = {Assessing Aspect-Oriented Programming and Design: Preliminary Results},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {1998},

  Address                  = {Vancouver, Canada},
  Month                    = may,
  Number                   = {TR-98-03},

  Abstract                 = {Aspect-oriented programming is a new software design and implementation technique proposed by researchers at Xerox PARC. This project is assessing the claims of aspect-oriented programming to improve the software development cycle for particular kinds of applications. The project is divided into three experiments, the first of which has been completed. These experiments have been designed to investigate, separately, such characteristics of aspect-oriented development as the creation of new aspect-oriented programs and ease of debugging aspect-oriented programs.},
  Url                      = {http://www.cs.ubc.ca/cgi-bin/tr/1998/TR-98-03.pdf}
}

@TechReport{1998:tr:walker:b,
  Title                    = {An Initial Assessment of Aspect-Oriented Programming},
  Author                   = {Robert J. Walker and Elisa L. A. Baniassad and Gail C. Murphy},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {1998},

  Address                  = {Vancouver, Canada},
  Month                    = aug,
  Number                   = {TR-98-12},

  Abstract                 = {The principle of separation of concerns has long been used by software engineers to manage the complexity of software system development. Programming languages help software engineers explicitly maintain the separation of some concerns in code. As another step towards increasing the scope of concerns that can be captured cleanly within the code, Kiczales and colleagues have introduced aspect-oriented programming. In aspect-oriented programming, explicit language support is provided to help modularize design decisions that cross-cut a functionally-decomposed program. Aspect-oriented programming is intended to make it easier to reason about, develop, and maintain certain kinds of application code. To investigate these claims, we conducted two exploratory experiments that considered the impact of aspect-oriented programming, as found in AspectJ version 0.1, on two common programming activities: debugging and change. Our experimental results provide insights into the usefulness and usability of aspect-oriented programming. Our results also raise questions about the characteristics of the interface between aspects and functionallydecomposed core code that are necessary to accrue programming benefits. Most notably, the separation provided by aspect-oriented programming seems most helpful when the interface is narrow (i.e., the separation is more complete); partial separation does not necessarily provide partial benefit.},
  Url                      = {http://www.cs.ubc.ca/cgi-bin/tr/1998/TR-98-12.pdf}
}

@InProceedings{2003:icse:walker,
  Title                    = {Empirical validation: What, why, when, and how},
  Author                   = {Robert J. Walker and Lionel C. Briand and David Notkin and Carolyn B. Seaman and Walter F. Tichy},
  Booktitle                = icse,
  Year                     = {2003},
  Note                     = {Panel},
  Pages                    = {721--722},

  Abstract                 = {All research requires validation, and where analytic solutions are not possible or not practical, empirical validation is necessary. Software engineering research covers a vast array of problems over which the level of maturity in our knowledge varies markedly. Opinions as to the methodology to apply to SE research appear to be in disagreement, as a large variety of possibilities exist [7]. Tichy promotes quantitative, controlled, statistically-analyzable experimentation [6]. Kitchenham et al. recognize the value of ``observational studies'' in addition to formal experimentation [3], but emphasize industrial-context, quantitative evaluation, and statistics. Seaman promotes the value of qualitative evaluation [5]. Murphy et al. suggest that a different treatment is needed for emerging technologies than for more mature ones [4]. Briand et al. state that ``each discipline needs to develop its own body of experience and strategies to answer its most pressing research questions'' [1, p. 398]. Without some consensus, an SE researcher is faced with a difficult task of convincing their peers that their selected methodology is appropriate, let alone the details of their validation. This panel session strives to address these issues in order to determine where a consensus does and does not exist. Brief synopses of each panelist's thoughts follow.},
  Doi                      = {10.1145/776816.776922}
}

@InProceedings{2006:msrw:walker,
  Title                    = {A lightweight approach to technical risk estimation via probabilistic impact analysis},
  Author                   = {Robert J. Walker and Reid Holmes and Ian Hedgeland and Puneet Kapur and Andrew Smith},
  Booktitle                = msrw,
  Year                     = {2006},
  Note                     = {International Conference on Software Engineering},
  Pages                    = {98--104},

  Abstract                 = {An evolutionary development approach is increasingly commonplace in industry but presents increased difficulties in risk management, for both technical and organizational reasons. In this context, technical risk is the product of the probability of a technical event and the cost of that event. This paper presents a technique for more objectively assessing and communicating technical risk in an evolutionary development setting that (1) operates atop weakly-estimated knowledge of the changes to be made, (2) analyzes the past change history and current structure of a system to estimate the probability of change propagation, and (3) can be discussed vertically within an organization both with development staff and high-level management. A tool realizing this technique has been developed for the Eclipse IDE.},
  Doi                      = {10.1145/1137983.1138008}
}

@TechReport{2006:tr:walker,
  Title                    = {A Lightweight Approach to Technical Risk Estimation via Probabilistic Impact Analysis},
  Author                   = {Robert J. Walker and Reid Holmes and Ian Hedgeland and Puneet Kapur and Andrew Smith},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2006},

  Address                  = {Calgary, Canada},
  Month                    = feb,
  Number                   = {2006-817-10},

  Abstract                 = {An evolutionary development approach is increasingly commonplace in industry but presents increased difficulties in risk management, for both technical and organizational reasons. In this context, technical risk is the product of the probability of a technical event and the cost of that event. This paper presents a technique for more objectively assessing and communicating technical risk in an evolutionary development setting that (1) operates atop weaklyestimated knowledge of the changes to be made, (2) analyzes the past change history and current structure of a system to estimate the probability of change propagation, and (3) can be discussed vertically within an organization both with development staff and high-level management. A tool realizing this technique has been developed for the Eclipse IDE.},
  Doi                      = {1880/46089}
}

@InProceedings{2001:asoc:walker,
  Title                    = {Joinpoints as ordered events: Towards applying implicit context to aspect-orientation},
  Author                   = {Robert J. Walker and Gail C. Murphy},
  Booktitle                = asoc,
  Year                     = {2001},
  Note                     = {International Conference on Software Engineering},
  Pages                    = {134--139},

  Abstract                 = {Implicit context is a recently introduced mechanism for improving source code structure, making components more reusable, and making their systems more evolvable. It worries about eliminating locally-unneeded knowledge of external components (extraneous embedded knowledge, or EEK). Aspect-oriented programming (AOP) is a separation of concerns mechanism. It worries about separating and encapsulating functionality that crosscuts the components of a system. AspectJ is a prototype AOP language.
Both approaches can be seen to manipulate software at joinpoints, points in the execution or lexical description of that software. Joinpoints and the related code to execute at them can be considered as an event-based system. The exposure of events in AspectJ differs from that in implicit context---AspectJ considers these events as immediate and largely independent, while implicit context considers them as historic and interrelated through its call history concept. We give an example of a system in which limiting the description of the events of interest to those currently available in AspectJ results in an error-prone and hard-to-evolve implementation, but in which the use of call history would lead to a more reusable and robust implementation. We also briefly examine the issue of EEK and its removal within this example.},
  Url                      = {http://www.research.ibm.com/hyperspace/workshops/icse2001/Papers/walker.pdf}
}

@InProceedings{2000:fse:walker,
  Title                    = {Implicit context: Easing software evolution and reuse},
  Author                   = {Robert J. Walker and Gail C. Murphy},
  Booktitle                = fse,
  Year                     = {2000},
  Pages                    = {69--78},

  Abstract                 = {Software systems should consist of simple, conceptually clean software components interacting along narrow, well-defined paths. All too often, this is not reality: complex components end up interacting for reasons unrelated to the functionality they provide. We refer to knowledge within a component that is not conceptually required for the individual behaviour of that component as extraneous embedded knowledge (EEK). EEK creeps into a system in many forms, including dependences upon particular names and the passing of extraneous parameters. This paper proposes the use of implicit context as a means for reducing EEK in systems by combining a mechanism to reflect upon what has happened in a system, through queries on the call history, with a mechanism for altering calls to and from a component. We demonstrate the benefits of implicit context by describing its use to reduce EEK in the Java Swing library.},
  Doi                      = {10.1145/355045.355054}
}

@InProceedings{1999:oorase:walker,
  Title                    = {Dynamic contextual reflection: A mechanism for software evolution and reuse},
  Author                   = {Robert J. Walker and Gail C. Murphy},
  Booktitle                = oorase,
  Year                     = {1999},
  Note                     = {ACM Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  Pages                    = {43--50},

  Abstract                 = {Current approaches to programming cause external information to be encoded into components. When this information is not of importance to the implementation of these components, but is an artifact of programming mechanisms, system structure suffers, resulting in greater difficulties in software evolution and reuse. We are investigating an approach to lessen the effects of such extraneous embedded knowledge by reflecting upon dynamic execution information and static structural information, which comprise the concept of context.},
  Url                      = {ftp://ftp.disi.unige.it/pub/person/CazzolaW/OORaSE99/043-050\%20Walker.ps.gz}
}

@TechReport{1999:tr:walker:b,
  Title                    = {Using Implicit Context to Ease Software Evolution and Reuse},
  Author                   = {Robert J. Walker and Gail C. Murphy},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {1999},

  Address                  = {Vancouver, Canada},
  Month                    = nov,
  Number                   = {TR-99-13},

  Abstract                 = {Software systems should consist of simple, conceptually clean components interacting along narrow, well-defined paths. All too often, this is not reality: complex components end up interacting for reasons unrelated to the functionality they provide. We refer to knowledge within a component that is not conceptually required for the individual behaviour of that component as extraneous embedded knowledge (EEK). EEK creeps in to a system in many forms, including dependences upon particular names and the passing of extraneous parameters. This paper proposes implicit context as a means for reducing EEK in systems. Implicit context combines a mechanism to reflect upon what has happened in a system through queries on the call history with a mechanism for altering calls to and from a component. We demonstrate the benefits of implicit context by describing its use to reduce EEK in the Java Swing library.},
  Url                      = {http://www.cs.ubc.ca/cgi-bin/tr/1999/TR-99-13.pdf}
}

@InProceedings{1998:oopsla:walker,
  Title                    = {Visualizing dynamic software system information through high-level models},
  Author                   = {Robert J. Walker and Gail C. Murphy and Bjorn Freeman-Benson and Darin Wright and Darin Swanson and Jeremy Isaak},
  Booktitle                = oopsla,
  Year                     = {1998},
  Pages                    = {271--283},

  Abstract                 = {Dynamic information collected as a software system executes can help software engineers perform some tasks on a system more effectively. To interpret the sizable amount of data generated from a system's execution, engineers require tool support. We have developed an off-line, flexible approach for visualizing the operation of an object-oriented system at the architectural level. This approach complements and extends existing profiling and visualization approaches available to engineers attempting to utilize dynamic information. In this paper, we describe the technique and discuss preliminary qualitative studies into its usefulness and usability. These studies were undertaken in the context of performance tuning tasks.},
  Doi                      = {10.1145/286936.286966}
}

@InProceedings{2000:cascon:walker,
  Title                    = {Efficient mapping of software system traces to architectural views},
  Author                   = {Robert J. Walker and Gail C. Murphy and Jeffrey Steinbok and Martin P. Robillard},
  Booktitle                = cascon,
  Year                     = {2000},
  Pages                    = {31--40},

  Abstract                 = {Information about a software system's execution can help a developer with many tasks, including software testing, performance tuning, and program understanding. In almost all cases, this dynamic information is reported in terms of source-level constructs, such as procedures and methods. For some software engineering tasks, source-level information is not optimal because there is a wide gap between the information presented (i.e., procedures) and the concepts of interest to the software developer (i.e., subsystems). One way to close this gap is to allow developers to investigate the execution information in terms of a higher-level, typically architectural, view. In this paper, we present an encoding technique for dynamic trace information that makes it tractable and efficient to manipulate a trace from a variety of different architecture-level viewpoints. To motivate the need for the encoding technique, we describe two tools that use the technique: a visualization tool and a path query tool. We present the encoding technique to enable the development of additional tools that manipulate dynamic information at a higher-level than source.},
  Doi                      = {10.1145/782034.782046}
}

@TechReport{2000:tr:walker:b,
  Title                    = {Efficient Mapping of Software System Traces to Architectural Views},
  Author                   = {Robert J. Walker and Gail C. Murphy and Jeffrey Steinbok and Martin P. Robillard},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {2000},

  Address                  = {Vancouver, Canada},
  Month                    = jul,
  Number                   = {TR-00-09},

  Abstract                 = {Information about a software system's execution can help a developer with many tasks, including software testing, performance tuning, and program understanding. In almost all cases, this dynamic information is reported in terms of source-level constructs, such as procedures and methods. For some software engineering tasks, source-level information is not optimal because there is a wide gap between the information presented (i.e., procedures) and the concepts of interest to the software developer (i.e., subsystems). One way to close this gap is to allow developers to investigate the execution information in terms of a higher-level, typically architectural, view. In this paper, we present a straightforward encoding technique for dynamic trace information that makes it tractable and efficient to manipulate a trace from a variety of different architecture-level viewpoints. We also describe how this encoding technique has been used to support the development of two tools: a visualization tool and a path query tool. We present this technique to enable the development of additional tools that manipulate dynamic information at a higherlevel than source.}
}

@InProceedings{2012:fse:walker,
  Title                    = {Do crosscutting concerns cause modularity problems?},
  Author                   = {Robert J. Walker and Shreya Rawal and Jonathan Sillito},
  Booktitle                = fse,
  Year                     = {2012},
  Pages                    = {49:1--49:11},

  Abstract                 = {It has been claimed that crosscutting concerns are pervasive and problematic, leading to difficulties in program comprehension, evolution, and long-term design degradation. To consider whether this theory bears out, we examine the patch history of the Mozilla project over a period of a decade to consider whether crosscutting concerns exist therein and whether we can see evidence of problems arising from them. Mozilla is an interesting case, due to its longevity; size; polylingual nature; and use of a patch review process, which maintains strong connections between issue reports and the patches that are intended to address each. We perform several statistical analyses of the over 200,000 patches submitted to address over 90,000 issues reported in this time period. We find that 90\% of patches show little or no evidence of scattering, that the scattering of a patch tends to decrease slightly upon review on average, and that the system shows at worst a slow increase of average scattering over time.}
}

@InProceedings{1999:alenex:walker,
  Title                    = {Practical point-in-polygon tests using {CSG} representations of polygons},
  Author                   = {Robert J. Walker and Jack Snoeyink},
  Booktitle                = alenex,
  Year                     = {1999},
  Pages                    = {114--123},
  Series                   = lncs,
  Volume                   = {1619},

  Abstract                 = {We investigate the use of a constructive solid geometry (CSG) representation in testing if a query point falls inside a polygon; in particular, we use a CSG tree whose leaves correspond to halfplanes defined by edges and whose internal nodes are intersections or unions of the regions defined by their subtrees. By preprocessing polygons into this representation, we obtain a linear-space data structure for point-in-polygon tests that has a tight inner loop that can prune unnecessary edge tests during evaluation. We experiment with opportunities to optimize the pruning by permuting children of nodes. The resulting test is less memory-intensive than grid methods and faster than existing one-shot methods. It also extends to ray-shooting in 3-space.},
  Doi                      = {10.1007/3-540-48518-X_7}
}

@TechReport{1999:tr:walker:a,
  Title                    = {Practical Point-in-Polygon Tests Using {CSG} Representations of Polygons},
  Author                   = {Robert J. Walker and Jack Snoeyink},
  Institution              = {Department of Computer Science, University of British Columbia},
  Year                     = {1999},

  Address                  = {Vancouver, Canada},
  Month                    = nov,
  Number                   = {TR-99-12},

  Abstract                 = {We investigate the use of a constructive solid geometry (CSG) representation of polygons in testing if points fall within them; this representation consists of a tree whose nodes are either Boolean operators or edges. By preprocessing the polygons, we seek (1) to construct a space-conserving data structure that supports point-in-polygon tests, (2) to prune as many edges as possible while maintaining the semantics of our tree, and (3) to obtain a tight inner loop to make testing the remaining edges as fast as possible. We utilize opportunities to optimize the pruning by permuting sibling nodes. We find that this process is less memory-intensive than the grid method and faster than existing one-shot methods.},
  Url                      = {http://www.cs.ubc.ca/cgi-bin/tr/1999/TR-99-12.pdf}
}

@InProceedings{1998:siggraphv:walker,
  Title                    = {Using {CSG} representations of polygons for practical point-in-polygon tests},
  Author                   = {Robert J. Walker and Jack Snoeyink},
  Booktitle                = siggraphv,
  Year                     = {1997},
  Note                     = {Technical sketch},
  Pages                    = {125},

  Doi                      = {10.1145/259081.259239}
}

@InProceedings{2004:fse:walker,
  Title                    = {Implementing protocols via declarative event patterns},
  Author                   = {Robert J. Walker and Kevin Viggers},
  Booktitle                = fse,
  Year                     = {2004},
  Pages                    = {159--169},

  Abstract                 = {This paper introduces declarative event patterns (DEPs) as a means to implement protocols while improving their traceability, comprehensibility, and maintainability. DEPs are descriptions of sequences of events in the execution of a system that include the ability to recognize properly nested event structures. DEPs allow a developer to describe a protocol at a high-level, without the need to express extraneous details. A developer can indicate that specific actions be taken when a given pattern occurs. DEPs are automatically translated into the appropriate instrumentation and automaton for recognizing a given pattern. Support for DEPs has been implemented in a proof-of-concept extension to the AspectJ language that is based on advanced compiler technology. A case study is described that compares the use of DEPs in the implementation of a protocol (FTP user authentication) to the use of a set of other approaches, both object-oriented and aspect-oriented.},
  Doi                      = {10.1145/1029894.1029918}
}

@TechReport{2004:tr:walker:a,
  Title                    = {Communication History Patterns: Direct Implementation of Protocol Specifications},
  Author                   = {Robert J. Walker and Kevin Viggers},
  Institution              = {Department of Computer Science, University of Calgary},
  Year                     = {2004},

  Address                  = {Calgary, Canada},
  Month                    = feb,
  Number                   = {2004-736-01},

  Abstract                 = {The interactions between separated crosscutting concerns and the base modularity of a system must be specified. These specifications include descriptions of the join points in the base code where behaviour is to be added or replaced. At present, the means available for describing join points generally treat each join point in isolation, rather than allowing multiple join points to be related to each other. When the interactions to be specified consist of complex, stateful communication protocols, the protocols must be hand-compiled into a description of isolated join points. As a result, errors can be introduced intro the implementation of the protocols, and the intent of each protocol can become obscured.
 This paper describes the use of communication history patterns to interrelate multiple join points when implementing complex interaction protocols. A practical language for communication history patterns is described, involving the addition of constructs and preprocessing to AspectJ. A case study is discussed that compares the use of this extended language to both a Java implementation and an unextended AspectJ implementation.},
  Doi                      = {1880/46084}
}

@Proceedings{2010:rsse,
  Title                    = {Proceedings of the 2nd International Workshop on Recommendation Systems for Software Engineering},
  Year                     = {2010},
  Editor                   = {Reid Holmes and Martin Robillard and Robert J. Walker and Thomas Zimmermann},
  Note                     = {ACM/IEEE International Conference on Software Engineering},

  Doi                      = {10.1145/1808920}
}

@Proceedings{2012:rsse,
  Title                    = {Proceedings of the 3rd International Workshop on Recommendation Systems for Software Engineering},
  Year                     = {2012},
  Editor                   = {Walid Maalej and Martin Robillard and Robert J. Walker and Thomas Zimmermann},
  Note                     = {ACM/IEEE International Conference on Software Engineering},

  Doi                      = {10.1109/RSSE.2012.6233398}
}

@Book{2013:book:robillard,
  Title                    = {Recommendation Systems for Software Engineering},
  Editor                   = {Martin Robillard and Walid Maalej and Robert J. Walker and Thomas Zimmermann},
  Publisher                = {Springer},
  Year                     = {2013},
  Note                     = {To appear},

  Owner                    = {walker},
  Timestamp                = {2012.12.13}
}

@Proceedings{2008:rsse,
  Title                    = {Proceedings of the International Workshop on Recommendation Systems for Software Engineering},
  Year                     = {2008},
  Editor                   = {Martin Robillard and Robert J. Walker and Thomas Zimmermann},
  Note                     = {ACM SIGSOFT International Symposium on Foundations of Software Engineering},

  Doi                      = {10.1145/1454247}
}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:cossette-fse-2012\;0\;2007:icsm:cossette\;2010:msc:kap
ur\;2010:oopsla:kapur\;;
1 ExplicitGroup:walker-fse-2012\;0\;2006:aosd:siadat\;2011:ecoop:taube
-schock\;;
}

