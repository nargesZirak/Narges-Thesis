\chapter{Related Work}  \label{rw}
In this chapter, we review related work to the topics of our study including: the application of logging in real-world software systems (Section~\ref{logging}), determining correspondences in source code (Section~\ref{ch7-corr}), data mining approaches to extract API usage patterns (Section~\ref{ch7-usage-patterns}), and  anti-unification and its application to detect structural correspondences and construct generalizations (Section~\ref{ch7-au}). %, and clustering (Section~\ref{ch7-clustering}).
% constructing the structural generalizations (Section~\ref{ch7-generalization}
\section{Usage of logging}  \label{logging}
Logging is a conventional programming practice to record a software system's runtime information that can be used in post-modern analysis to trace the root causes of systems' activities. Log analysis is most often performed for failure diagnosis, system behavioral understanding, system security monitoring, and performance diagnostics purposes as described below:
\begin{itemize} [leftmargin=0.5in]
\item \textbf{Log analysis for failure diagnosis:} \citet{xu2009detecting} use statistical techniques to learn a decision tree based signature from console logs and then utilize the signature to diagnose anomalies. \tool{SherLog} \cite{yuan2010sherlog} uses failure log messages to infer the source code paths that might have been executed during a failure.
\item \textbf{Log analysis for system behaviour understanding:} \citet{fu2013contextual} present an approach for understanding system behaviour through contextual analysis of logs. They first extracted execution patterns reflected by a sequence of system logs and then utilized the patterns to find contextual factors from logs that causes a specific system behavior. The Linux Trace Toolkit \cite{yaghmour2000measuringandcharacter} was created to record and analyze system behavior by providing an efficient kernel-level event logging infrastructure. A more flexible approach is taken by \tool{DTrace}~\cite{cantrill2004dynamic} which allows dynamic modification of kernel code.
\item \textbf{Log analysis for system security monitoring:} \citet{bishop1989model} proposes a formal model of system's security monitoring using logging and auditing. \citet{peisert2007toward} have developed a model that demonstrates a mechanism for extracting logging information to detect how an intrusion occurs in software systems.
%have developed?
% Jiang et al. [2009b] present an approach to automatically detect problems of load tests by mining the execution logs of an application. Many software systems must be load tested for their functional and performance problems diagnosis.
\item \textbf{Log analysis for performance diagnosis:} \citet{nagaraj2012structured} developed an automated tool to assist developers in diagnosis and correction of performance issues in distributed systems by analyzing system behaviours extracted from the log data.
\end{itemize}

\citet{jiang2009understanding} study the effectiveness of logging in problem diagnosis. Their study shows that customer problems in software systems with logging resolve faster than those without logging by investigating the correlations between failure root causes and diagnosis time. Despite the importance of logging for software development and maintenance, few studies have been conducted in pursuit of understanding logging usage in real-world software. \citet{yuan2012characterizing} provides a quantitative characteristic study to investigate log message modifications on four open-source software systems by mining their revision history. Their study shows that developers spend great effort modifying log statements as after-thoughts, which indicates that they are not satisfied with the log quality in their first attempt. They also characterize where developers spend most of their time in modifying the log messages.

\citet{yuan2012conservative} study the problem of lack of log messages for error diagnosis and suggests to log when generic error conditions happens. \tool{LogEnhancer} \cite{yuan2012improving} automatically enhances existing log messages by detecting variables containing important values and inserting them into the log messages. However, these studies only consider source code fragments containing bugs that are needed to be logged and do not consider the other code fragments with no bugs but still needed to be logged. Moreover, these studies mainly research log message modifications and potential enhancements of them, however, the focus of this study is on understanding where logging calls are used in source code.
% where to log
% Sadi

\section{Correspondence}  \label{ch7-corr}
Several studies have been conducted to find the similarities and differences between source code fragments. \citet{baxter1998clone} develop an algorithm to detect code clones in source code that uses hash functions to partition subtrees of ASTs of a program and then find common subtrees in the same partition through a tree comparison algorithm. \citet{apiwattanapong2004differencing} present a top-down approach to detect differences and correspondences between two versions of a Java program, through comparison of the control flow graphs created from source code. \citet{holmes2005strathcona} recommend relevant code snippet examples from a source code repository for the sake of helping developers to find examples of how to use an API by heuristically matching the structure of the code under development with the code in the repository. \tool{Coogle} \cite{sager2006detecting} was developed to detect similar Java classes by converting ASTs to a normalized format and then comparing them through tree similarity algorithms. However, none of these approaches construct a detailed view of structural generalizations needed in our context.
%explain more why not ??
%Umami

\citet{2014:uofc:cossette} present a new approach, called matching via structural generalization (MSG), to recommend replacements for API migration. They used \tool{Jigsaw} to find structural correspondences, however, the proposed algorithm does not suffice to construct structural generalizations that represent the detailed commonalities and differences of a set of source code fragments with special attention to log statements, which is required to solve our problem.
%. It also does not take the required constraints in determining correspondences needed to solve our problem.

\section{API usages patterns}  \label{ch7-usage-patterns}
Various data mining approaches have been used to extract API usages patterns out of source code such as unordered pattern mining and sequential pattern mining \cite{robillard2013automated}. Unordered pattern mining, such as association rule mining and itemset mining, extracts a set of API usage rules without considering their order \cite{agrawal1994fast}. \tool{CodeWeb} \cite{2000:icse:michail} uses data mining association rules to identify reuse patterns between a source code under development and a specific library. \tool{PR-Miner} \cite{li2005pr} uses frequent itemset mining to extract implicit programming rules from source code and detect violations. The sequential pattern mining technique is different from the unordered one in the way that it considers the order of API usage. As an example, \tool{MAPO} \cite{2006:msr:xie} combines frequent subsequence mining with clustering to extract API usage patterns from source code.

Another technique for extracting API usage patterns is through statistical source code analysis. For example, \tool{PopCon} \cite{holmes2008newbie} is a tool developed to help developers understanding how to use APIs in their source code through calculating popularity statistics for each API of a library. \citet{acharya2007mining} present a framework to extract API usage scenarios as partial orders, as specifications were extracted from frequent partial orders. They adapted a compile time model checker to generate control-flow-sensitive static traces of APIs, from which API usage scenarios were extracted. However, none of these approaches suffice to construct detailed structural generalizations needed in our context.
%However, none of these approaches suffice to determine the detailed structural correspondences.
\section{Anti-unification}  \label{ch7-au}
Anti-unification is the problem of finding the most specific generalization of two terms. First-order syntactical anti-unification was introduced by \citet{plotkin1970note} and \citet{reynolds1970transformational}, independently. \citet{burghardt1996implementing} extend the notion of anti-unification to E-anti-unification to incorporate background knowledge to syntactical anti-unification, which is required for some applications. Anti-unification and its extensions have been applied in various studies for program analysis. \citet{bulychev2009evaluation} suggest an anti-unification algorithm to detect clones in ASTs. Their approach consists of three stages: first, identifying similar statements through anti-unification and grouping them into clusters; second, determining similar sequences of statements with the same cluster identifier; third, refining candidate statement sequences using an anti-unification based similarity measurement to generate final clones. However, their approach does not construct structural generalizations.
%?

\citet{2007:esec_fse:cottrell} propose \tool{Breakaway} to automatically determine structural correspondences between a pair of ASTs to create a generalized correspondence view. However, their approach does not allow the determination of the best structural correspondence for each AST node required to our context. \citet{2008:fse:cottrell} developed \tool{Jigsaw} to help developers integrate small-scale reused code into their own source code by determining structural correspondences through the application of higher-order anti-unification modulo theories. Although I used the \tool{Jigsaw} framework to find potential correspondences between AST nodes, their approach does not suffice to construct structural generalizations of a set of source code fragments by considering the limitations of this study in determining correspondences.

%\item Sadi [2011] proposed an anti-unification algorithm to characterize the location of logging usages in the source code, however,
%\begin{itemize} [leftmargin=.3in]
%\item he has not applied anti-unification appropriately!!! \RW{You would need to explain what that means}
% Higher-order anti-unification modulo theories is formally undecidable [Burghardt, 2005].

%\section{Clustering}  \label{ch7-clustering}

%optimal clusters
%Clustering is an unsupervised machine mining technique that aims to organize a collection of data into clusters, such that intra-cluster similarity is maximized and the inter-cluster similarity is minimized \cite{karypis1999chameleon,grira2004unsupervised}. We divided existing clustering approaches into two major categories: partitional clustering and hierarchical clustering. Partitional clustering try to classify a data set into $k$ clusters such that the partition optimizes a pre-determined criterion \cite{karypis1999chameleon}. The most popular partitional clustering algorithm is $k$-means, which repeatedly assigns each data point to a cluster with the nearest centroid and computes the new cluster centroids accordingly until a pre-determined number of clusters is obtained \cite{bouguettaya2015efficient}. However, the $k$-means clustering algorithm is not a good fit to our problem, as it requires to predefine the number of clusters we need to come up with, which is not reasonable in our context. %?

%Hierarchical clustering algorithms produce a nested grouping of clusters, with single point clusters at the bottom and an all-inclusive cluster at the top \cite{karypis1999chameleon}. Agglomerative hierarchical clustering is one of the main stream clustering methods \cite{day1984efficient} and has applications in document retrieval \cite{voorhees1986implementing} and information retrieval from a search engine query log \cite{beeferman2000agglomerative}. It starts with singleton clusters, where each contains one data point. Then it repeatedly merges the two most similar clusters to form a bigger one until a pre-determined number of clusters is obtained or the similarity between the closest clusters becomes below a pre-determined threshold value. Hierarchical clustering algorithms work implicitly or explicitly with the $n \times n$ similarity matrix such that an element in row $i$ and column $j$ represents the similarity between the $i$th and the $j$th clusters \cite{karypis1999chameleon}.
% agglomerative hierarchical or hierarchical ???

%There are various versions of agglomerative hierarchical algorithms that mainly differ in how they update the similarity between clusters. There are various methods to measure the similarity between clusters, such as single linkage, complete linkage, average linkage, and centroids [Rasmussen, 1992] \RW{Put into bibtex}. In the single linkage method, the similarity is measured by the similarity of the closest pair of data points of two clusters. In the complete linkage method, the similarity is computed by the similarity of the farthest pair of data points of two clusters. In the average linkage method, the similarity is measured by the average of all pairwise similarities between data points of two clusters. In the centroids methods, each cluster is represented by a centroid of all data points in the cluster, and the similarity between two clusters is measured by the similarity of the clusters' centroids.
%However, in our application, each cluster is composed of one AUAST, and the similarity between two clusters is measured by the similarity between the clusters' AUASTs, which is the ratio of the number of common pieces over the total number of pieces of their anti-unifier.
% (see Section~\ref{meth-similarity}).
%optimal clusters- read dr. denzinger email
%similarity and distance two sides of a coin
% k-means,the predetermined criterion is met
% Hierarchical clustering approaches produce clusters of higher quality, however, these approaches suffer from high time cost[Bouguettay]

\section{Summary}  \label{back-summary}
%machine learning, other generalization approaches

Despite the great importance of logging and its various applications in software development and maintenance, few studies have focused on understanding logging usage in source code.
Some work has been done on characterizing log messages modifications made by developers and to help them enhance the content of log messages. However, to my knowledge, no study has been conducted on characterizing where logging is used in source code via structural generalization and clustering. Several data mining and statistical source code analysis techniques have been used to extract API usage patterns, however, none of them enable us to construct the detailed structural generalizations of a set of source code fragments. On the other hand, using higher-order anti-unification modulo theories and an agglomerative hierarchical clustering algorithm allow us to construct generalizations representing the commonalities and differences between ASTs of logged Java methods and grouping them into clusters based on structural correspondence.

